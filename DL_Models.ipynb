{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c05165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e33567",
   "metadata": {},
   "source": [
    "# Load ETa data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93c9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_myb = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Myb', parse_dates = ['Date'])\n",
    "US_Sne = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Sne', parse_dates = ['Date'])\n",
    "US_Snf = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Snf', parse_dates = ['Date'])\n",
    "US_Tw1 = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Tw1', parse_dates = ['Date'])\n",
    "US_Tw2 = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Tw2', parse_dates = ['Date'])\n",
    "US_Tw3 = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Tw3', parse_dates = ['Date'])\n",
    "US_Tw4 = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Tw4', parse_dates = ['Date'])\n",
    "US_Tw5 = pd.read_excel('/home/jovyan/Team4/Data/AmeriFlux_ETa/All_Tower_Clean_data.xlsx', sheet_name = 'US-Tw5', parse_dates = ['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e76e4",
   "metadata": {},
   "source": [
    "# Load Vegetation Indices and Thermal Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55cb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_EVI = pd.read_csv('/home/jovyan/Team4/Data/MODIS_Indices/MODIS_NDVI_EVI_Extraction.csv', parse_dates = ['Date'])\n",
    "FPAR_LAI = pd.read_csv('/home/jovyan/Team4/Data/MODIS_Indices/MODIS_FPAR_LAI_Extraction.csv', parse_dates = ['Date'])\n",
    "LST_DLST = pd.read_csv('/home/jovyan/Team4/Data/MODIS_Indices/MODIS_LST_DLST_Extraction.csv', parse_dates = ['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f7627",
   "metadata": {},
   "source": [
    "# Merge and Interpolate all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6019365",
   "metadata": {},
   "source": [
    "# (a) Station US-myb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c1dbf3-89b4-442c-a20c-2e6dfcdc7ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>TA</th>\n",
       "      <th>SW_IN</th>\n",
       "      <th>LW_IN</th>\n",
       "      <th>VPD</th>\n",
       "      <th>PA</th>\n",
       "      <th>P</th>\n",
       "      <th>WS</th>\n",
       "      <th>LE</th>\n",
       "      <th>H</th>\n",
       "      <th>ETa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>10.767</td>\n",
       "      <td>64.252</td>\n",
       "      <td>345.117</td>\n",
       "      <td>2.622</td>\n",
       "      <td>102.445</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.328</td>\n",
       "      <td>57.7050</td>\n",
       "      <td>23.932700</td>\n",
       "      <td>2.013958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>11.230</td>\n",
       "      <td>86.497</td>\n",
       "      <td>332.308</td>\n",
       "      <td>2.044</td>\n",
       "      <td>102.244</td>\n",
       "      <td>0.219</td>\n",
       "      <td>1.208</td>\n",
       "      <td>38.9442</td>\n",
       "      <td>1.402940</td>\n",
       "      <td>1.359789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.749</td>\n",
       "      <td>96.941</td>\n",
       "      <td>290.054</td>\n",
       "      <td>1.599</td>\n",
       "      <td>101.939</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.889</td>\n",
       "      <td>54.8205</td>\n",
       "      <td>10.706200</td>\n",
       "      <td>1.907795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>8.396</td>\n",
       "      <td>132.200</td>\n",
       "      <td>274.652</td>\n",
       "      <td>2.136</td>\n",
       "      <td>101.889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.482</td>\n",
       "      <td>57.7050</td>\n",
       "      <td>23.932700</td>\n",
       "      <td>2.009414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.649</td>\n",
       "      <td>88.983</td>\n",
       "      <td>295.321</td>\n",
       "      <td>2.222</td>\n",
       "      <td>101.942</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.958</td>\n",
       "      <td>38.9442</td>\n",
       "      <td>1.402940</td>\n",
       "      <td>1.355159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.718</td>\n",
       "      <td>111.213</td>\n",
       "      <td>296.163</td>\n",
       "      <td>2.399</td>\n",
       "      <td>100.901</td>\n",
       "      <td>4.919</td>\n",
       "      <td>4.279</td>\n",
       "      <td>48.6873</td>\n",
       "      <td>10.726900</td>\n",
       "      <td>1.694305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>5.996</td>\n",
       "      <td>91.804</td>\n",
       "      <td>302.650</td>\n",
       "      <td>2.463</td>\n",
       "      <td>100.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.299</td>\n",
       "      <td>35.7856</td>\n",
       "      <td>7.910330</td>\n",
       "      <td>1.243293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>6.157</td>\n",
       "      <td>38.341</td>\n",
       "      <td>326.851</td>\n",
       "      <td>0.883</td>\n",
       "      <td>100.451</td>\n",
       "      <td>6.607</td>\n",
       "      <td>3.564</td>\n",
       "      <td>20.9495</td>\n",
       "      <td>0.176889</td>\n",
       "      <td>0.727956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.927</td>\n",
       "      <td>131.792</td>\n",
       "      <td>296.484</td>\n",
       "      <td>2.349</td>\n",
       "      <td>100.915</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.475</td>\n",
       "      <td>50.0932</td>\n",
       "      <td>8.005720</td>\n",
       "      <td>1.743576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>6.506</td>\n",
       "      <td>113.818</td>\n",
       "      <td>281.141</td>\n",
       "      <td>1.984</td>\n",
       "      <td>100.882</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.042</td>\n",
       "      <td>39.3826</td>\n",
       "      <td>13.610400</td>\n",
       "      <td>1.368926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4383 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Site_Name      TA    SW_IN    LW_IN    VPD       PA  \\\n",
       "0    2010-01-01  Mayberry Wetland  10.767   64.252  345.117  2.622  102.445   \n",
       "1    2010-01-02  Mayberry Wetland  11.230   86.497  332.308  2.044  102.244   \n",
       "2    2010-01-03  Mayberry Wetland   7.749   96.941  290.054  1.599  101.939   \n",
       "3    2010-01-04  Mayberry Wetland   8.396  132.200  274.652  2.136  101.889   \n",
       "4    2010-01-05  Mayberry Wetland   7.649   88.983  295.321  2.222  101.942   \n",
       "...         ...               ...     ...      ...      ...    ...      ...   \n",
       "4378 2021-12-27  Mayberry Wetland   7.718  111.213  296.163  2.399  100.901   \n",
       "4379 2021-12-28  Mayberry Wetland   5.996   91.804  302.650  2.463  100.750   \n",
       "4380 2021-12-29  Mayberry Wetland   6.157   38.341  326.851  0.883  100.451   \n",
       "4381 2021-12-30  Mayberry Wetland   7.927  131.792  296.484  2.349  100.915   \n",
       "4382 2021-12-31  Mayberry Wetland   6.506  113.818  281.141  1.984  100.882   \n",
       "\n",
       "          P     WS       LE          H       ETa  \n",
       "0     0.001  1.328  57.7050  23.932700  2.013958  \n",
       "1     0.219  1.208  38.9442   1.402940  1.359789  \n",
       "2     0.005  1.889  54.8205  10.706200  1.907795  \n",
       "3     0.000  1.482  57.7050  23.932700  2.009414  \n",
       "4     0.003  0.958  38.9442   1.402940  1.355159  \n",
       "...     ...    ...      ...        ...       ...  \n",
       "4378  4.919  4.279  48.6873  10.726900  1.694305  \n",
       "4379  0.000  2.299  35.7856   7.910330  1.243293  \n",
       "4380  6.607  3.564  20.9495   0.176889  0.727956  \n",
       "4381  0.002  1.475  50.0932   8.005720  1.743576  \n",
       "4382  0.000  2.042  39.3826  13.610400  1.368926  \n",
       "\n",
       "[4383 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_myb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d75f5dc6-900e-4b1b-8046-8a0680ba40ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-18</td>\n",
       "      <td>Twitchell Island</td>\n",
       "      <td>0.089751</td>\n",
       "      <td>0.140238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>Twitchell Island</td>\n",
       "      <td>0.382246</td>\n",
       "      <td>0.091054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-05</td>\n",
       "      <td>Twitchell Island</td>\n",
       "      <td>0.397163</td>\n",
       "      <td>0.138107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>Twitchell Island</td>\n",
       "      <td>0.413690</td>\n",
       "      <td>0.167054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-21</td>\n",
       "      <td>Twitchell Island</td>\n",
       "      <td>0.396433</td>\n",
       "      <td>0.170609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10965</th>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>0.524978</td>\n",
       "      <td>0.230040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10966</th>\n",
       "      <td>2023-12-03</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>0.519279</td>\n",
       "      <td>0.198819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>0.557664</td>\n",
       "      <td>0.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>0.446847</td>\n",
       "      <td>0.192397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>0.492647</td>\n",
       "      <td>0.136456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10970 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Site_Name      NDVI       EVI\n",
       "0     2000-02-18  Twitchell Island  0.089751  0.140238\n",
       "1     2000-02-26  Twitchell Island  0.382246  0.091054\n",
       "2     2000-03-05  Twitchell Island  0.397163  0.138107\n",
       "3     2000-03-13  Twitchell Island  0.413690  0.167054\n",
       "4     2000-03-21  Twitchell Island  0.396433  0.170609\n",
       "...          ...               ...       ...       ...\n",
       "10965 2023-11-25  Mayberry Wetland  0.524978  0.230040\n",
       "10966 2023-12-03  Mayberry Wetland  0.519279  0.198819\n",
       "10967 2023-12-11  Mayberry Wetland  0.557664  0.217900\n",
       "10968 2023-12-19  Mayberry Wetland  0.446847  0.192397\n",
       "10969 2023-12-27  Mayberry Wetland  0.492647  0.136456\n",
       "\n",
       "[10970 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDVI_EVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3304e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-myb staton\n",
    "US_myb1 = US_myb.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_myb2 = US_myb1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_myb_all_variables = US_myb2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_myb_all_variables['NDVI'] = US_myb_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_myb_all_variables['EVI'] = US_myb_all_variables['EVI'].interpolate(method='linear')\n",
    "US_myb_all_variables['FPAR'] = US_myb_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_myb_all_variables['LAI'] = US_myb_all_variables['LAI'].interpolate(method='linear')\n",
    "US_myb_all_variables['LST'] = US_myb_all_variables['LST'].interpolate(method='linear')\n",
    "US_myb_all_variables['DLST'] = US_myb_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a928b4-f03c-4159-b7a0-6681f271e72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>TA</th>\n",
       "      <th>SW_IN</th>\n",
       "      <th>LW_IN</th>\n",
       "      <th>VPD</th>\n",
       "      <th>PA</th>\n",
       "      <th>P</th>\n",
       "      <th>WS</th>\n",
       "      <th>LE</th>\n",
       "      <th>H</th>\n",
       "      <th>ETa</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>FPAR</th>\n",
       "      <th>LAI</th>\n",
       "      <th>LST</th>\n",
       "      <th>DLST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>10.767</td>\n",
       "      <td>64.252</td>\n",
       "      <td>345.117</td>\n",
       "      <td>2.622</td>\n",
       "      <td>102.445</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.328</td>\n",
       "      <td>57.7050</td>\n",
       "      <td>23.932700</td>\n",
       "      <td>2.013958</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>-0.025297</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>11.230</td>\n",
       "      <td>86.497</td>\n",
       "      <td>332.308</td>\n",
       "      <td>2.044</td>\n",
       "      <td>102.244</td>\n",
       "      <td>0.219</td>\n",
       "      <td>1.208</td>\n",
       "      <td>38.9442</td>\n",
       "      <td>1.402940</td>\n",
       "      <td>1.359789</td>\n",
       "      <td>0.044595</td>\n",
       "      <td>-0.001610</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.749</td>\n",
       "      <td>96.941</td>\n",
       "      <td>290.054</td>\n",
       "      <td>1.599</td>\n",
       "      <td>101.939</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.889</td>\n",
       "      <td>54.8205</td>\n",
       "      <td>10.706200</td>\n",
       "      <td>1.907795</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>8.396</td>\n",
       "      <td>132.200</td>\n",
       "      <td>274.652</td>\n",
       "      <td>2.136</td>\n",
       "      <td>101.889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.482</td>\n",
       "      <td>57.7050</td>\n",
       "      <td>23.932700</td>\n",
       "      <td>2.009414</td>\n",
       "      <td>0.144084</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.649</td>\n",
       "      <td>88.983</td>\n",
       "      <td>295.321</td>\n",
       "      <td>2.222</td>\n",
       "      <td>101.942</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.958</td>\n",
       "      <td>38.9442</td>\n",
       "      <td>1.402940</td>\n",
       "      <td>1.355159</td>\n",
       "      <td>0.193829</td>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.718</td>\n",
       "      <td>111.213</td>\n",
       "      <td>296.163</td>\n",
       "      <td>2.399</td>\n",
       "      <td>100.901</td>\n",
       "      <td>4.919</td>\n",
       "      <td>4.279</td>\n",
       "      <td>48.6873</td>\n",
       "      <td>10.726900</td>\n",
       "      <td>1.694305</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.600</td>\n",
       "      <td>282.76</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>5.996</td>\n",
       "      <td>91.804</td>\n",
       "      <td>302.650</td>\n",
       "      <td>2.463</td>\n",
       "      <td>100.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.299</td>\n",
       "      <td>35.7856</td>\n",
       "      <td>7.910330</td>\n",
       "      <td>1.243293</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.575</td>\n",
       "      <td>282.76</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>6.157</td>\n",
       "      <td>38.341</td>\n",
       "      <td>326.851</td>\n",
       "      <td>0.883</td>\n",
       "      <td>100.451</td>\n",
       "      <td>6.607</td>\n",
       "      <td>3.564</td>\n",
       "      <td>20.9495</td>\n",
       "      <td>0.176889</td>\n",
       "      <td>0.727956</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.550</td>\n",
       "      <td>282.76</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.927</td>\n",
       "      <td>131.792</td>\n",
       "      <td>296.484</td>\n",
       "      <td>2.349</td>\n",
       "      <td>100.915</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.475</td>\n",
       "      <td>50.0932</td>\n",
       "      <td>8.005720</td>\n",
       "      <td>1.743576</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.525</td>\n",
       "      <td>282.76</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>6.506</td>\n",
       "      <td>113.818</td>\n",
       "      <td>281.141</td>\n",
       "      <td>1.984</td>\n",
       "      <td>100.882</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.042</td>\n",
       "      <td>39.3826</td>\n",
       "      <td>13.610400</td>\n",
       "      <td>1.368926</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.500</td>\n",
       "      <td>282.76</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4383 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Site_Name      TA    SW_IN    LW_IN    VPD       PA  \\\n",
       "0    2010-01-01  Mayberry Wetland  10.767   64.252  345.117  2.622  102.445   \n",
       "1    2010-01-02  Mayberry Wetland  11.230   86.497  332.308  2.044  102.244   \n",
       "2    2010-01-03  Mayberry Wetland   7.749   96.941  290.054  1.599  101.939   \n",
       "3    2010-01-04  Mayberry Wetland   8.396  132.200  274.652  2.136  101.889   \n",
       "4    2010-01-05  Mayberry Wetland   7.649   88.983  295.321  2.222  101.942   \n",
       "...         ...               ...     ...      ...      ...    ...      ...   \n",
       "4378 2021-12-27  Mayberry Wetland   7.718  111.213  296.163  2.399  100.901   \n",
       "4379 2021-12-28  Mayberry Wetland   5.996   91.804  302.650  2.463  100.750   \n",
       "4380 2021-12-29  Mayberry Wetland   6.157   38.341  326.851  0.883  100.451   \n",
       "4381 2021-12-30  Mayberry Wetland   7.927  131.792  296.484  2.349  100.915   \n",
       "4382 2021-12-31  Mayberry Wetland   6.506  113.818  281.141  1.984  100.882   \n",
       "\n",
       "          P     WS       LE          H       ETa      NDVI       EVI    FPAR  \\\n",
       "0     0.001  1.328  57.7050  23.932700  2.013958 -0.005150 -0.025297  0.0800   \n",
       "1     0.219  1.208  38.9442   1.402940  1.359789  0.044595 -0.001610  0.0675   \n",
       "2     0.005  1.889  54.8205  10.706200  1.907795  0.094340  0.022077  0.0550   \n",
       "3     0.000  1.482  57.7050  23.932700  2.009414  0.144084  0.045764  0.0425   \n",
       "4     0.003  0.958  38.9442   1.402940  1.355159  0.193829  0.069451  0.0300   \n",
       "...     ...    ...      ...        ...       ...       ...       ...     ...   \n",
       "4378  4.919  4.279  48.6873  10.726900  1.694305  0.526618  0.258294  0.3400   \n",
       "4379  0.000  2.299  35.7856   7.910330  1.243293  0.526618  0.258294  0.3325   \n",
       "4380  6.607  3.564  20.9495   0.176889  0.727956  0.526618  0.258294  0.3250   \n",
       "4381  0.002  1.475  50.0932   8.005720  1.743576  0.526618  0.258294  0.3175   \n",
       "4382  0.000  2.042  39.3826  13.610400  1.368926  0.526618  0.258294  0.3100   \n",
       "\n",
       "        LAI     LST      DLST  \n",
       "0     0.100     NaN  276.8800  \n",
       "1     0.075     NaN  277.4775  \n",
       "2     0.050     NaN  278.0750  \n",
       "3     0.025     NaN  278.6725  \n",
       "4     0.000     NaN  279.2700  \n",
       "...     ...     ...       ...  \n",
       "4378  0.600  282.76  276.1600  \n",
       "4379  0.575  282.76  276.1600  \n",
       "4380  0.550  282.76  276.1600  \n",
       "4381  0.525  282.76  276.1600  \n",
       "4382  0.500  282.76  276.1600  \n",
       "\n",
       "[4383 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_myb_all_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceab5328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>TA</th>\n",
       "      <th>SW_IN</th>\n",
       "      <th>LW_IN</th>\n",
       "      <th>VPD</th>\n",
       "      <th>PA</th>\n",
       "      <th>P</th>\n",
       "      <th>WS</th>\n",
       "      <th>LE</th>\n",
       "      <th>H</th>\n",
       "      <th>ETa</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>FPAR</th>\n",
       "      <th>LAI</th>\n",
       "      <th>LST</th>\n",
       "      <th>DLST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.164</td>\n",
       "      <td>55.548</td>\n",
       "      <td>324.628</td>\n",
       "      <td>1.218</td>\n",
       "      <td>102.047</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.135</td>\n",
       "      <td>54.8205</td>\n",
       "      <td>10.706200</td>\n",
       "      <td>1.906734</td>\n",
       "      <td>0.392808</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.700</td>\n",
       "      <td>286.560</td>\n",
       "      <td>281.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.238</td>\n",
       "      <td>90.177</td>\n",
       "      <td>312.783</td>\n",
       "      <td>1.253</td>\n",
       "      <td>102.001</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.152</td>\n",
       "      <td>57.7050</td>\n",
       "      <td>23.932700</td>\n",
       "      <td>2.007202</td>\n",
       "      <td>0.404308</td>\n",
       "      <td>0.174980</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.600</td>\n",
       "      <td>286.235</td>\n",
       "      <td>281.1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>8.645</td>\n",
       "      <td>114.430</td>\n",
       "      <td>314.842</td>\n",
       "      <td>1.970</td>\n",
       "      <td>101.687</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1.407</td>\n",
       "      <td>38.9442</td>\n",
       "      <td>1.402940</td>\n",
       "      <td>1.356443</td>\n",
       "      <td>0.415807</td>\n",
       "      <td>0.185759</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.500</td>\n",
       "      <td>285.910</td>\n",
       "      <td>280.7250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>13.259</td>\n",
       "      <td>70.536</td>\n",
       "      <td>345.593</td>\n",
       "      <td>3.234</td>\n",
       "      <td>101.395</td>\n",
       "      <td>6.481</td>\n",
       "      <td>2.986</td>\n",
       "      <td>54.8205</td>\n",
       "      <td>10.706200</td>\n",
       "      <td>1.917844</td>\n",
       "      <td>0.427307</td>\n",
       "      <td>0.196539</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.400</td>\n",
       "      <td>285.585</td>\n",
       "      <td>280.2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>13.055</td>\n",
       "      <td>110.283</td>\n",
       "      <td>309.813</td>\n",
       "      <td>3.241</td>\n",
       "      <td>101.848</td>\n",
       "      <td>2.554</td>\n",
       "      <td>3.701</td>\n",
       "      <td>57.7050</td>\n",
       "      <td>23.932700</td>\n",
       "      <td>2.018362</td>\n",
       "      <td>0.438807</td>\n",
       "      <td>0.207319</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.300</td>\n",
       "      <td>285.260</td>\n",
       "      <td>279.7900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.718</td>\n",
       "      <td>111.213</td>\n",
       "      <td>296.163</td>\n",
       "      <td>2.399</td>\n",
       "      <td>100.901</td>\n",
       "      <td>4.919</td>\n",
       "      <td>4.279</td>\n",
       "      <td>48.6873</td>\n",
       "      <td>10.726900</td>\n",
       "      <td>1.694305</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.600</td>\n",
       "      <td>282.760</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>5.996</td>\n",
       "      <td>91.804</td>\n",
       "      <td>302.650</td>\n",
       "      <td>2.463</td>\n",
       "      <td>100.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.299</td>\n",
       "      <td>35.7856</td>\n",
       "      <td>7.910330</td>\n",
       "      <td>1.243293</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.575</td>\n",
       "      <td>282.760</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>6.157</td>\n",
       "      <td>38.341</td>\n",
       "      <td>326.851</td>\n",
       "      <td>0.883</td>\n",
       "      <td>100.451</td>\n",
       "      <td>6.607</td>\n",
       "      <td>3.564</td>\n",
       "      <td>20.9495</td>\n",
       "      <td>0.176889</td>\n",
       "      <td>0.727956</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.550</td>\n",
       "      <td>282.760</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>7.927</td>\n",
       "      <td>131.792</td>\n",
       "      <td>296.484</td>\n",
       "      <td>2.349</td>\n",
       "      <td>100.915</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.475</td>\n",
       "      <td>50.0932</td>\n",
       "      <td>8.005720</td>\n",
       "      <td>1.743576</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.525</td>\n",
       "      <td>282.760</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Mayberry Wetland</td>\n",
       "      <td>6.506</td>\n",
       "      <td>113.818</td>\n",
       "      <td>281.141</td>\n",
       "      <td>1.984</td>\n",
       "      <td>100.882</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.042</td>\n",
       "      <td>39.3826</td>\n",
       "      <td>13.610400</td>\n",
       "      <td>1.368926</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.258294</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.500</td>\n",
       "      <td>282.760</td>\n",
       "      <td>276.1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4375 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Site_Name      TA    SW_IN    LW_IN    VPD       PA  \\\n",
       "8    2010-01-09  Mayberry Wetland   7.164   55.548  324.628  1.218  102.047   \n",
       "9    2010-01-10  Mayberry Wetland   7.238   90.177  312.783  1.253  102.001   \n",
       "10   2010-01-11  Mayberry Wetland   8.645  114.430  314.842  1.970  101.687   \n",
       "11   2010-01-12  Mayberry Wetland  13.259   70.536  345.593  3.234  101.395   \n",
       "12   2010-01-13  Mayberry Wetland  13.055  110.283  309.813  3.241  101.848   \n",
       "...         ...               ...     ...      ...      ...    ...      ...   \n",
       "4378 2021-12-27  Mayberry Wetland   7.718  111.213  296.163  2.399  100.901   \n",
       "4379 2021-12-28  Mayberry Wetland   5.996   91.804  302.650  2.463  100.750   \n",
       "4380 2021-12-29  Mayberry Wetland   6.157   38.341  326.851  0.883  100.451   \n",
       "4381 2021-12-30  Mayberry Wetland   7.927  131.792  296.484  2.349  100.915   \n",
       "4382 2021-12-31  Mayberry Wetland   6.506  113.818  281.141  1.984  100.882   \n",
       "\n",
       "          P     WS       LE          H       ETa      NDVI       EVI    FPAR  \\\n",
       "8     0.012  1.135  54.8205  10.706200  1.906734  0.392808  0.164200  0.4100   \n",
       "9     0.042  1.152  57.7050  23.932700  2.007202  0.404308  0.174980  0.3625   \n",
       "10    0.003  1.407  38.9442   1.402940  1.356443  0.415807  0.185759  0.3150   \n",
       "11    6.481  2.986  54.8205  10.706200  1.917844  0.427307  0.196539  0.2675   \n",
       "12    2.554  3.701  57.7050  23.932700  2.018362  0.438807  0.207319  0.2200   \n",
       "...     ...    ...      ...        ...       ...       ...       ...     ...   \n",
       "4378  4.919  4.279  48.6873  10.726900  1.694305  0.526618  0.258294  0.3400   \n",
       "4379  0.000  2.299  35.7856   7.910330  1.243293  0.526618  0.258294  0.3325   \n",
       "4380  6.607  3.564  20.9495   0.176889  0.727956  0.526618  0.258294  0.3250   \n",
       "4381  0.002  1.475  50.0932   8.005720  1.743576  0.526618  0.258294  0.3175   \n",
       "4382  0.000  2.042  39.3826  13.610400  1.368926  0.526618  0.258294  0.3100   \n",
       "\n",
       "        LAI      LST      DLST  \n",
       "8     0.700  286.560  281.6600  \n",
       "9     0.600  286.235  281.1925  \n",
       "10    0.500  285.910  280.7250  \n",
       "11    0.400  285.585  280.2575  \n",
       "12    0.300  285.260  279.7900  \n",
       "...     ...      ...       ...  \n",
       "4378  0.600  282.760  276.1600  \n",
       "4379  0.575  282.760  276.1600  \n",
       "4380  0.550  282.760  276.1600  \n",
       "4381  0.525  282.760  276.1600  \n",
       "4382  0.500  282.760  276.1600  \n",
       "\n",
       "[4375 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_myb_all_variables.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13fca6",
   "metadata": {},
   "source": [
    "# (b) Station US-Sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082e6daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-Sne staton\n",
    "US_Sne1 = US_Sne.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Sne2 = US_Sne1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Sne_all_variables = US_Sne2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_Sne_all_variables['NDVI'] = US_Sne_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_Sne_all_variables['EVI'] = US_Sne_all_variables['EVI'].interpolate(method='linear')\n",
    "US_Sne_all_variables['FPAR'] = US_Sne_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_Sne_all_variables['LAI'] = US_Sne_all_variables['LAI'].interpolate(method='linear')\n",
    "US_Sne_all_variables['LST'] = US_Sne_all_variables['LST'].interpolate(method='linear')\n",
    "US_Sne_all_variables['DLST'] = US_Sne_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b1e23d-3005-4543-bd7a-4a36a12b0ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>TA</th>\n",
       "      <th>SW_IN</th>\n",
       "      <th>LW_IN</th>\n",
       "      <th>VPD</th>\n",
       "      <th>PA</th>\n",
       "      <th>P</th>\n",
       "      <th>WS</th>\n",
       "      <th>LE</th>\n",
       "      <th>H</th>\n",
       "      <th>ETa</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>FPAR</th>\n",
       "      <th>LAI</th>\n",
       "      <th>LST</th>\n",
       "      <th>DLST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>4.562</td>\n",
       "      <td>121.854</td>\n",
       "      <td>67592.543</td>\n",
       "      <td>4.105</td>\n",
       "      <td>102.031</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.307</td>\n",
       "      <td>100.67900</td>\n",
       "      <td>59.54540</td>\n",
       "      <td>3.493119</td>\n",
       "      <td>0.044001</td>\n",
       "      <td>0.044272</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.30</td>\n",
       "      <td>280.46</td>\n",
       "      <td>274.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>5.591</td>\n",
       "      <td>108.846</td>\n",
       "      <td>41856.119</td>\n",
       "      <td>3.564</td>\n",
       "      <td>101.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.014</td>\n",
       "      <td>93.67310</td>\n",
       "      <td>64.76100</td>\n",
       "      <td>3.253218</td>\n",
       "      <td>0.094367</td>\n",
       "      <td>0.061113</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.25</td>\n",
       "      <td>280.92</td>\n",
       "      <td>274.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>7.111</td>\n",
       "      <td>99.851</td>\n",
       "      <td>36097.240</td>\n",
       "      <td>3.415</td>\n",
       "      <td>101.097</td>\n",
       "      <td>0.242</td>\n",
       "      <td>2.331</td>\n",
       "      <td>104.59700</td>\n",
       "      <td>60.05590</td>\n",
       "      <td>3.637848</td>\n",
       "      <td>0.144733</td>\n",
       "      <td>0.077953</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.20</td>\n",
       "      <td>281.38</td>\n",
       "      <td>275.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>9.261</td>\n",
       "      <td>50.295</td>\n",
       "      <td>9249.724</td>\n",
       "      <td>2.731</td>\n",
       "      <td>100.596</td>\n",
       "      <td>4.851</td>\n",
       "      <td>3.242</td>\n",
       "      <td>100.67900</td>\n",
       "      <td>59.54540</td>\n",
       "      <td>3.508751</td>\n",
       "      <td>0.195098</td>\n",
       "      <td>0.094794</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.15</td>\n",
       "      <td>281.84</td>\n",
       "      <td>276.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>10.365</td>\n",
       "      <td>66.386</td>\n",
       "      <td>13488.554</td>\n",
       "      <td>2.206</td>\n",
       "      <td>100.416</td>\n",
       "      <td>14.210</td>\n",
       "      <td>4.340</td>\n",
       "      <td>93.67310</td>\n",
       "      <td>64.76100</td>\n",
       "      <td>3.268025</td>\n",
       "      <td>0.245464</td>\n",
       "      <td>0.111635</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.10</td>\n",
       "      <td>282.30</td>\n",
       "      <td>276.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>8.590</td>\n",
       "      <td>108.534</td>\n",
       "      <td>289.719</td>\n",
       "      <td>2.512</td>\n",
       "      <td>101.274</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.424</td>\n",
       "      <td>15.84940</td>\n",
       "      <td>5.74683</td>\n",
       "      <td>0.552013</td>\n",
       "      <td>0.378635</td>\n",
       "      <td>0.211987</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.30</td>\n",
       "      <td>284.04</td>\n",
       "      <td>280.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>8.991</td>\n",
       "      <td>60.822</td>\n",
       "      <td>316.441</td>\n",
       "      <td>2.140</td>\n",
       "      <td>101.063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.618</td>\n",
       "      <td>9.35841</td>\n",
       "      <td>0.92189</td>\n",
       "      <td>0.326065</td>\n",
       "      <td>0.378635</td>\n",
       "      <td>0.211987</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.30</td>\n",
       "      <td>284.04</td>\n",
       "      <td>280.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>8.840</td>\n",
       "      <td>122.420</td>\n",
       "      <td>262.485</td>\n",
       "      <td>4.852</td>\n",
       "      <td>102.313</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.240</td>\n",
       "      <td>14.82940</td>\n",
       "      <td>5.65073</td>\n",
       "      <td>0.516610</td>\n",
       "      <td>0.378635</td>\n",
       "      <td>0.211987</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.30</td>\n",
       "      <td>284.04</td>\n",
       "      <td>280.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>7.348</td>\n",
       "      <td>112.852</td>\n",
       "      <td>290.982</td>\n",
       "      <td>3.047</td>\n",
       "      <td>102.535</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>13.57340</td>\n",
       "      <td>6.98916</td>\n",
       "      <td>0.472185</td>\n",
       "      <td>0.378635</td>\n",
       "      <td>0.211987</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.30</td>\n",
       "      <td>284.04</td>\n",
       "      <td>280.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>Sherman Island Restored Wetland</td>\n",
       "      <td>9.888</td>\n",
       "      <td>112.487</td>\n",
       "      <td>30724.195</td>\n",
       "      <td>3.888</td>\n",
       "      <td>102.082</td>\n",
       "      <td>0.235</td>\n",
       "      <td>3.711</td>\n",
       "      <td>12.61840</td>\n",
       "      <td>6.35908</td>\n",
       "      <td>0.440025</td>\n",
       "      <td>0.378635</td>\n",
       "      <td>0.211987</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.30</td>\n",
       "      <td>284.04</td>\n",
       "      <td>280.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1827 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                        Site_Name      TA    SW_IN      LW_IN  \\\n",
       "0    2016-01-01  Sherman Island Restored Wetland   4.562  121.854  67592.543   \n",
       "1    2016-01-02  Sherman Island Restored Wetland   5.591  108.846  41856.119   \n",
       "2    2016-01-03  Sherman Island Restored Wetland   7.111   99.851  36097.240   \n",
       "3    2016-01-04  Sherman Island Restored Wetland   9.261   50.295   9249.724   \n",
       "4    2016-01-05  Sherman Island Restored Wetland  10.365   66.386  13488.554   \n",
       "...         ...                              ...     ...      ...        ...   \n",
       "1822 2020-12-27  Sherman Island Restored Wetland   8.590  108.534    289.719   \n",
       "1823 2020-12-28  Sherman Island Restored Wetland   8.991   60.822    316.441   \n",
       "1824 2020-12-29  Sherman Island Restored Wetland   8.840  122.420    262.485   \n",
       "1825 2020-12-30  Sherman Island Restored Wetland   7.348  112.852    290.982   \n",
       "1826 2020-12-31  Sherman Island Restored Wetland   9.888  112.487  30724.195   \n",
       "\n",
       "        VPD       PA       P     WS         LE         H       ETa      NDVI  \\\n",
       "0     4.105  102.031   0.000  2.307  100.67900  59.54540  3.493119  0.044001   \n",
       "1     3.564  101.728   0.000  2.014   93.67310  64.76100  3.253218  0.094367   \n",
       "2     3.415  101.097   0.242  2.331  104.59700  60.05590  3.637848  0.144733   \n",
       "3     2.731  100.596   4.851  3.242  100.67900  59.54540  3.508751  0.195098   \n",
       "4     2.206  100.416  14.210  4.340   93.67310  64.76100  3.268025  0.245464   \n",
       "...     ...      ...     ...    ...        ...       ...       ...       ...   \n",
       "1822  2.512  101.274   0.000  1.424   15.84940   5.74683  0.552013  0.378635   \n",
       "1823  2.140  101.063   0.000  1.618    9.35841   0.92189  0.326065  0.378635   \n",
       "1824  4.852  102.313   0.000  1.240   14.82940   5.65073  0.516610  0.378635   \n",
       "1825  3.047  102.535   0.000  0.994   13.57340   6.98916  0.472185  0.378635   \n",
       "1826  3.888  102.082   0.235  3.711   12.61840   6.35908  0.440025  0.378635   \n",
       "\n",
       "           EVI   FPAR   LAI     LST    DLST  \n",
       "0     0.044272  0.210  0.30  280.46  274.02  \n",
       "1     0.061113  0.180  0.25  280.92  274.73  \n",
       "2     0.077953  0.150  0.20  281.38  275.44  \n",
       "3     0.094794  0.120  0.15  281.84  276.15  \n",
       "4     0.111635  0.090  0.10  282.30  276.86  \n",
       "...        ...    ...   ...     ...     ...  \n",
       "1822  0.211987  0.265  0.30  284.04  280.58  \n",
       "1823  0.211987  0.260  0.30  284.04  280.58  \n",
       "1824  0.211987  0.255  0.30  284.04  280.58  \n",
       "1825  0.211987  0.250  0.30  284.04  280.58  \n",
       "1826  0.211987  0.250  0.30  284.04  280.58  \n",
       "\n",
       "[1827 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_Sne_all_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b25bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_Sne_all_variables.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a007e4",
   "metadata": {},
   "source": [
    "# (c) Station US-Snf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd50a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-Snf staton\n",
    "US_Snf1 = US_Snf.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Snf2 = US_Snf1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Snf_all_variables = US_Snf2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_Snf_all_variables['NDVI'] = US_Snf_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_Snf_all_variables['EVI'] = US_Snf_all_variables['EVI'].interpolate(method='linear')\n",
    "US_Snf_all_variables['FPAR'] = US_Snf_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_Snf_all_variables['LAI'] = US_Snf_all_variables['LAI'].interpolate(method='linear')\n",
    "US_Snf_all_variables['LST'] = US_Snf_all_variables['LST'].interpolate(method='linear')\n",
    "US_Snf_all_variables['DLST'] = US_Snf_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad67cd83-e3c9-4ad4-bdfd-a2bdcb490a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>TA</th>\n",
       "      <th>SW_IN</th>\n",
       "      <th>LW_IN</th>\n",
       "      <th>VPD</th>\n",
       "      <th>PA</th>\n",
       "      <th>P</th>\n",
       "      <th>WS</th>\n",
       "      <th>LE</th>\n",
       "      <th>H</th>\n",
       "      <th>ETa</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>FPAR</th>\n",
       "      <th>LAI</th>\n",
       "      <th>LST</th>\n",
       "      <th>DLST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>8.672</td>\n",
       "      <td>105.110</td>\n",
       "      <td>306.303</td>\n",
       "      <td>3.795</td>\n",
       "      <td>102.176</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.462</td>\n",
       "      <td>90.3802</td>\n",
       "      <td>49.3101</td>\n",
       "      <td>3.148063</td>\n",
       "      <td>0.135987</td>\n",
       "      <td>0.037431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>9.942</td>\n",
       "      <td>91.754</td>\n",
       "      <td>316.341</td>\n",
       "      <td>4.814</td>\n",
       "      <td>102.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.554</td>\n",
       "      <td>93.8716</td>\n",
       "      <td>40.6014</td>\n",
       "      <td>3.273630</td>\n",
       "      <td>0.124482</td>\n",
       "      <td>0.045644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>9.212</td>\n",
       "      <td>49.666</td>\n",
       "      <td>323.643</td>\n",
       "      <td>2.930</td>\n",
       "      <td>101.663</td>\n",
       "      <td>1.995</td>\n",
       "      <td>1.660</td>\n",
       "      <td>86.8875</td>\n",
       "      <td>48.6979</td>\n",
       "      <td>3.027964</td>\n",
       "      <td>0.112977</td>\n",
       "      <td>0.053857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>13.096</td>\n",
       "      <td>87.158</td>\n",
       "      <td>343.596</td>\n",
       "      <td>3.239</td>\n",
       "      <td>101.771</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.136</td>\n",
       "      <td>90.3802</td>\n",
       "      <td>49.3101</td>\n",
       "      <td>3.161375</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.062071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>12.999</td>\n",
       "      <td>39.281</td>\n",
       "      <td>354.824</td>\n",
       "      <td>2.169</td>\n",
       "      <td>102.103</td>\n",
       "      <td>2.915</td>\n",
       "      <td>2.453</td>\n",
       "      <td>93.8716</td>\n",
       "      <td>40.6014</td>\n",
       "      <td>3.283195</td>\n",
       "      <td>0.089966</td>\n",
       "      <td>0.070284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>8.362</td>\n",
       "      <td>109.051</td>\n",
       "      <td>289.460</td>\n",
       "      <td>3.568</td>\n",
       "      <td>101.213</td>\n",
       "      <td>0.062</td>\n",
       "      <td>2.107</td>\n",
       "      <td>95.2808</td>\n",
       "      <td>80.6578</td>\n",
       "      <td>3.317778</td>\n",
       "      <td>-0.045752</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>9.026</td>\n",
       "      <td>72.358</td>\n",
       "      <td>311.330</td>\n",
       "      <td>3.607</td>\n",
       "      <td>100.962</td>\n",
       "      <td>1.792</td>\n",
       "      <td>2.239</td>\n",
       "      <td>88.8858</td>\n",
       "      <td>81.3151</td>\n",
       "      <td>3.097054</td>\n",
       "      <td>-0.045752</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>7.091</td>\n",
       "      <td>125.659</td>\n",
       "      <td>262.392</td>\n",
       "      <td>5.465</td>\n",
       "      <td>102.295</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.154</td>\n",
       "      <td>89.1449</td>\n",
       "      <td>78.4129</td>\n",
       "      <td>3.100370</td>\n",
       "      <td>-0.045752</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>6.795</td>\n",
       "      <td>108.496</td>\n",
       "      <td>297.045</td>\n",
       "      <td>2.954</td>\n",
       "      <td>102.552</td>\n",
       "      <td>0.686</td>\n",
       "      <td>2.210</td>\n",
       "      <td>95.2808</td>\n",
       "      <td>80.6578</td>\n",
       "      <td>3.312838</td>\n",
       "      <td>-0.045752</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>Sherman Barn</td>\n",
       "      <td>11.970</td>\n",
       "      <td>180.990</td>\n",
       "      <td>292.303</td>\n",
       "      <td>6.310</td>\n",
       "      <td>102.082</td>\n",
       "      <td>0.241</td>\n",
       "      <td>3.636</td>\n",
       "      <td>88.8858</td>\n",
       "      <td>81.3151</td>\n",
       "      <td>3.105760</td>\n",
       "      <td>-0.045752</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     Site_Name      TA    SW_IN    LW_IN    VPD       PA  \\\n",
       "0    2018-01-01  Sherman Barn   8.672  105.110  306.303  3.795  102.176   \n",
       "1    2018-01-02  Sherman Barn   9.942   91.754  316.341  4.814  102.075   \n",
       "2    2018-01-03  Sherman Barn   9.212   49.666  323.643  2.930  101.663   \n",
       "3    2018-01-04  Sherman Barn  13.096   87.158  343.596  3.239  101.771   \n",
       "4    2018-01-05  Sherman Barn  12.999   39.281  354.824  2.169  102.103   \n",
       "...         ...           ...     ...      ...      ...    ...      ...   \n",
       "1091 2020-12-27  Sherman Barn   8.362  109.051  289.460  3.568  101.213   \n",
       "1092 2020-12-28  Sherman Barn   9.026   72.358  311.330  3.607  100.962   \n",
       "1093 2020-12-29  Sherman Barn   7.091  125.659  262.392  5.465  102.295   \n",
       "1094 2020-12-30  Sherman Barn   6.795  108.496  297.045  2.954  102.552   \n",
       "1095 2020-12-31  Sherman Barn  11.970  180.990  292.303  6.310  102.082   \n",
       "\n",
       "          P     WS       LE        H       ETa      NDVI       EVI  FPAR  LAI  \\\n",
       "0     0.002  1.462  90.3802  49.3101  3.148063  0.135987  0.037431   NaN  NaN   \n",
       "1     0.000  1.554  93.8716  40.6014  3.273630  0.124482  0.045644   NaN  NaN   \n",
       "2     1.995  1.660  86.8875  48.6979  3.027964  0.112977  0.053857   NaN  NaN   \n",
       "3     0.291  2.136  90.3802  49.3101  3.161375  0.101471  0.062071   NaN  NaN   \n",
       "4     2.915  2.453  93.8716  40.6014  3.283195  0.089966  0.070284   NaN  NaN   \n",
       "...     ...    ...      ...      ...       ...       ...       ...   ...  ...   \n",
       "1091  0.062  2.107  95.2808  80.6578  3.317778 -0.045752 -0.008239   0.4  0.9   \n",
       "1092  1.792  2.239  88.8858  81.3151  3.097054 -0.045752 -0.008239   0.4  0.9   \n",
       "1093  0.000  2.154  89.1449  78.4129  3.100370 -0.045752 -0.008239   0.4  0.9   \n",
       "1094  0.686  2.210  95.2808  80.6578  3.312838 -0.045752 -0.008239   0.4  0.9   \n",
       "1095  0.241  3.636  88.8858  81.3151  3.105760 -0.045752 -0.008239   0.4  0.9   \n",
       "\n",
       "      LST  DLST  \n",
       "0     NaN   NaN  \n",
       "1     NaN   NaN  \n",
       "2     NaN   NaN  \n",
       "3     NaN   NaN  \n",
       "4     NaN   NaN  \n",
       "...   ...   ...  \n",
       "1091  NaN   NaN  \n",
       "1092  NaN   NaN  \n",
       "1093  NaN   NaN  \n",
       "1094  NaN   NaN  \n",
       "1095  NaN   NaN  \n",
       "\n",
       "[1096 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_Snf_all_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18aa247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_Snf_all_variables.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437aa7e",
   "metadata": {},
   "source": [
    "# (d) Station US-Tw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee97bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-Tw1 staton\n",
    "US_Tw1_1 = US_Tw1.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw1_2 = US_Tw1_1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw1_all_variables = US_Tw1_2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_Tw1_all_variables['NDVI'] = US_Tw1_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_Tw1_all_variables['EVI'] = US_Tw1_all_variables['EVI'].interpolate(method='linear')\n",
    "US_Tw1_all_variables['FPAR'] = US_Tw1_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_Tw1_all_variables['LAI'] = US_Tw1_all_variables['LAI'].interpolate(method='linear')\n",
    "US_Tw1_all_variables['LST'] = US_Tw1_all_variables['LST'].interpolate(method='linear')\n",
    "US_Tw1_all_variables['DLST'] = US_Tw1_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de298c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_Tw1_all_variables.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9c730a-aede-49ef-ba72-8bc867e54738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3653, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_Tw1_all_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b5dea",
   "metadata": {},
   "source": [
    "# (e) Station US-Tw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a079977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-Tw2 staton\n",
    "US_Tw2_1 = US_Tw2.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw2_2 = US_Tw2_1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw2_all_variables = US_Tw2_2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_Tw2_all_variables['NDVI'] = US_Tw2_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_Tw2_all_variables['EVI'] = US_Tw2_all_variables['EVI'].interpolate(method='linear')\n",
    "US_Tw2_all_variables['FPAR'] = US_Tw2_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_Tw2_all_variables['LAI'] = US_Tw2_all_variables['LAI'].interpolate(method='linear')\n",
    "US_Tw2_all_variables['LST'] = US_Tw2_all_variables['LST'].interpolate(method='linear')\n",
    "US_Tw2_all_variables['DLST'] = US_Tw2_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cff5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_Tw2_all_variables.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "790f1f40-c3e7-4cbd-8428-51609f9b9884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 18)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_Tw2_all_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280d6b0",
   "metadata": {},
   "source": [
    "# (f) Station US-Tw3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b504368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-Tw3 staton\n",
    "US_Tw3_1 = US_Tw3.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw3_2 = US_Tw3_1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw3_all_variables = US_Tw3_2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_Tw3_all_variables['NDVI'] = US_Tw3_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_Tw3_all_variables['EVI'] = US_Tw3_all_variables['EVI'].interpolate(method='linear')\n",
    "US_Tw3_all_variables['FPAR'] = US_Tw3_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_Tw3_all_variables['LAI'] = US_Tw3_all_variables['LAI'].interpolate(method='linear')\n",
    "US_Tw3_all_variables['LST'] = US_Tw3_all_variables['LST'].interpolate(method='linear')\n",
    "US_Tw3_all_variables['DLST'] = US_Tw3_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a48ce1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_Tw3_all_variables.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4798f445-4680-4e99-87fd-baae3b1ea701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2191, 18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_Tw3_all_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfd694",
   "metadata": {},
   "source": [
    "# (f) Station US-Tw4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c57551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-Tw4 staton\n",
    "US_Tw4_1 = US_Tw4.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw4_2 = US_Tw4_1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw4_all_variables = US_Tw4_2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_Tw4_all_variables['NDVI'] = US_Tw4_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_Tw4_all_variables['EVI'] = US_Tw4_all_variables['EVI'].interpolate(method='linear')\n",
    "US_Tw4_all_variables['FPAR'] = US_Tw4_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_Tw4_all_variables['LAI'] = US_Tw4_all_variables['LAI'].interpolate(method='linear')\n",
    "US_Tw4_all_variables['LST'] = US_Tw4_all_variables['LST'].interpolate(method='linear')\n",
    "US_Tw4_all_variables['DLST'] = US_Tw4_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d33913ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_Tw4_all_variables.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a34da2ff-950b-4e30-8759-78f497e42fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3287, 18)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_Tw4_all_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381df57",
   "metadata": {},
   "source": [
    "# (g) Station US-Tw5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "243edf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather variables with vegetation indices for US-Tw5 staton\n",
    "US_Tw5_1 = US_Tw5.merge(NDVI_EVI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw5_2 = US_Tw5_1.merge(FPAR_LAI, how = 'left', on = ['Date', 'Site_Name'])\n",
    "US_Tw5_all_variables = US_Tw5_2.merge(LST_DLST, how = 'left', on = ['Date', 'Site_Name'])\n",
    "\n",
    "# Perform linear interpolation on NDVI, EVI, FPAR, LAI, LST, and DLST columns\n",
    "US_Tw5_all_variables['NDVI'] = US_Tw5_all_variables['NDVI'].interpolate(method='linear')\n",
    "US_Tw5_all_variables['EVI'] = US_Tw5_all_variables['EVI'].interpolate(method='linear')\n",
    "US_Tw5_all_variables['FPAR'] = US_Tw5_all_variables['FPAR'].interpolate(method='linear')\n",
    "US_Tw5_all_variables['LAI'] = US_Tw5_all_variables['LAI'].interpolate(method='linear')\n",
    "US_Tw5_all_variables['LST'] = US_Tw5_all_variables['LST'].interpolate(method='linear')\n",
    "US_Tw5_all_variables['DLST'] = US_Tw5_all_variables['DLST'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4258b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if any Nan value contains\n",
    "US_Tw5_all_variables.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc10ab7d-751b-45b9-b90e-df3e0033da75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 18)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_Tw5_all_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e27ff",
   "metadata": {},
   "source": [
    "# Concatenate all the stations data except US-Tw5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f0a701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat ([US_myb_all_variables, US_Sne_all_variables, US_Snf_all_variables, US_Tw1_all_variables, US_Tw2_all_variables, US_Tw3_all_variables, US_Tw4_all_variables], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9410d812-df20-422c-8b91-1dcecb323686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Date', 'Site_Name', 'LE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecf5ceed-70e6-4568-a6c0-934bb68d3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1719dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['ETa'])\n",
    "y = df['ETa']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2a633",
   "metadata": {},
   "source": [
    "# 1. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c55a70-e2ab-4225-9e7c-fa7900c08b9d",
   "metadata": {},
   "source": [
    "# 1.1 Simpel Artificial Neural Network (Only one hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "487729a1-825b-4437-8850-ccdcc46c6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Splitting data into training and testing\n",
    "X = df.drop(columns = ['ETa'])\n",
    "y = df['ETa']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 20)\n",
    "\n",
    "# Normalization of data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "84e8131d-9b12-4b45-8274-bacf74050d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n",
    "# build a input layer\n",
    "from keras.layers import Input\n",
    "\n",
    "# retrieve the dimension of input features\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape = (num_features,))\n",
    "\n",
    "# create a hidden layer\n",
    "L = Dense (24, activation = 'relu') (input_layer)\n",
    "\n",
    "# output layer and model summary\n",
    "output_layer = Dense (1, activation = 'linear') (L)\n",
    "\n",
    "# Build a model\n",
    "from keras.models import Model\n",
    "model = Model(input_layer, output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e999cd2f-4518-41ac-a1e3-f2c7cebb2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m232/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 10.5245 - mean_absolute_error: 2.5315\n",
      "Epoch 1: val_loss improved from inf to 1.62566, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.5947 - mean_absolute_error: 2.3699 - val_loss: 1.6257 - val_mean_absolute_error: 0.9124\n",
      "Epoch 2/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 1.5444 - mean_absolute_error: 0.8674\n",
      "Epoch 2: val_loss improved from 1.62566 to 1.32784, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 1.5325 - mean_absolute_error: 0.8625 - val_loss: 1.3278 - val_mean_absolute_error: 0.8009\n",
      "Epoch 3/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 1.3464 - mean_absolute_error: 0.7701\n",
      "Epoch 3: val_loss improved from 1.32784 to 1.20143, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 1.3332 - mean_absolute_error: 0.7677 - val_loss: 1.2014 - val_mean_absolute_error: 0.7354\n",
      "Epoch 4/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 1.2110 - mean_absolute_error: 0.7266\n",
      "Epoch 4: val_loss improved from 1.20143 to 1.13990, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 1.2059 - mean_absolute_error: 0.7248 - val_loss: 1.1399 - val_mean_absolute_error: 0.7065\n",
      "Epoch 5/200\n",
      "\u001b[1m248/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 1.2177 - mean_absolute_error: 0.7174\n",
      "Epoch 5: val_loss improved from 1.13990 to 1.11748, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 1.2058 - mean_absolute_error: 0.7139 - val_loss: 1.1175 - val_mean_absolute_error: 0.6905\n",
      "Epoch 6/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 1.1435 - mean_absolute_error: 0.6914\n",
      "Epoch 6: val_loss improved from 1.11748 to 1.08146, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 1.1357 - mean_absolute_error: 0.6887 - val_loss: 1.0815 - val_mean_absolute_error: 0.6751\n",
      "Epoch 7/200\n",
      "\u001b[1m226/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 1.1820 - mean_absolute_error: 0.6816\n",
      "Epoch 7: val_loss improved from 1.08146 to 1.06782, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1616 - mean_absolute_error: 0.6783 - val_loss: 1.0678 - val_mean_absolute_error: 0.6648\n",
      "Epoch 8/200\n",
      "\u001b[1m244/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 1.0062 - mean_absolute_error: 0.6456\n",
      "Epoch 8: val_loss improved from 1.06782 to 1.04289, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - loss: 1.0123 - mean_absolute_error: 0.6465 - val_loss: 1.0429 - val_mean_absolute_error: 0.6578\n",
      "Epoch 9/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 1.0549 - mean_absolute_error: 0.6498\n",
      "Epoch 9: val_loss improved from 1.04289 to 1.03471, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 1.0536 - mean_absolute_error: 0.6503 - val_loss: 1.0347 - val_mean_absolute_error: 0.6544\n",
      "Epoch 10/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 1.0042 - mean_absolute_error: 0.6441\n",
      "Epoch 10: val_loss improved from 1.03471 to 1.02070, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 1.0084 - mean_absolute_error: 0.6443 - val_loss: 1.0207 - val_mean_absolute_error: 0.6455\n",
      "Epoch 11/200\n",
      "\u001b[1m230/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 1.0009 - mean_absolute_error: 0.6422\n",
      "Epoch 11: val_loss improved from 1.02070 to 1.00569, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0077 - mean_absolute_error: 0.6424 - val_loss: 1.0057 - val_mean_absolute_error: 0.6390\n",
      "Epoch 12/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 1.0280 - mean_absolute_error: 0.6417\n",
      "Epoch 12: val_loss improved from 1.00569 to 0.99328, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 1.0252 - mean_absolute_error: 0.6411 - val_loss: 0.9933 - val_mean_absolute_error: 0.6379\n",
      "Epoch 13/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 1.0125 - mean_absolute_error: 0.6373\n",
      "Epoch 13: val_loss improved from 0.99328 to 0.98839, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 1.0103 - mean_absolute_error: 0.6366 - val_loss: 0.9884 - val_mean_absolute_error: 0.6394\n",
      "Epoch 14/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 1.0928 - mean_absolute_error: 0.6525\n",
      "Epoch 14: val_loss improved from 0.98839 to 0.98060, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0731 - mean_absolute_error: 0.6485 - val_loss: 0.9806 - val_mean_absolute_error: 0.6335\n",
      "Epoch 15/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.9749 - mean_absolute_error: 0.6332\n",
      "Epoch 15: val_loss improved from 0.98060 to 0.96508, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.9768 - mean_absolute_error: 0.6324 - val_loss: 0.9651 - val_mean_absolute_error: 0.6239\n",
      "Epoch 16/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 0.9498 - mean_absolute_error: 0.6120\n",
      "Epoch 16: val_loss improved from 0.96508 to 0.95549, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.9541 - mean_absolute_error: 0.6139 - val_loss: 0.9555 - val_mean_absolute_error: 0.6235\n",
      "Epoch 17/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 0.9949 - mean_absolute_error: 0.6312\n",
      "Epoch 17: val_loss did not improve from 0.95549\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.9926 - mean_absolute_error: 0.6305 - val_loss: 0.9560 - val_mean_absolute_error: 0.6162\n",
      "Epoch 18/200\n",
      "\u001b[1m219/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.9092 - mean_absolute_error: 0.6151\n",
      "Epoch 18: val_loss improved from 0.95549 to 0.94509, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9202 - mean_absolute_error: 0.6164 - val_loss: 0.9451 - val_mean_absolute_error: 0.6130\n",
      "Epoch 19/200\n",
      "\u001b[1m222/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.9142 - mean_absolute_error: 0.6062\n",
      "Epoch 19: val_loss did not improve from 0.94509\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.9202 - mean_absolute_error: 0.6090 - val_loss: 0.9479 - val_mean_absolute_error: 0.6224\n",
      "Epoch 20/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.9120 - mean_absolute_error: 0.6112\n",
      "Epoch 20: val_loss improved from 0.94509 to 0.93959, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.9204 - mean_absolute_error: 0.6131 - val_loss: 0.9396 - val_mean_absolute_error: 0.6131\n",
      "Epoch 21/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.9873 - mean_absolute_error: 0.6217\n",
      "Epoch 21: val_loss improved from 0.93959 to 0.93242, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.9818 - mean_absolute_error: 0.6213 - val_loss: 0.9324 - val_mean_absolute_error: 0.6155\n",
      "Epoch 22/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.8581 - mean_absolute_error: 0.5975\n",
      "Epoch 22: val_loss did not improve from 0.93242\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.8717 - mean_absolute_error: 0.6006 - val_loss: 0.9364 - val_mean_absolute_error: 0.6229\n",
      "Epoch 23/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 0.9280 - mean_absolute_error: 0.6255\n",
      "Epoch 23: val_loss did not improve from 0.93242\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.9316 - mean_absolute_error: 0.6250 - val_loss: 0.9347 - val_mean_absolute_error: 0.6284\n",
      "Epoch 24/200\n",
      "\u001b[1m244/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.9242 - mean_absolute_error: 0.6134\n",
      "Epoch 24: val_loss improved from 0.93242 to 0.92597, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9266 - mean_absolute_error: 0.6138 - val_loss: 0.9260 - val_mean_absolute_error: 0.6223\n",
      "Epoch 25/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.9500 - mean_absolute_error: 0.6207\n",
      "Epoch 25: val_loss improved from 0.92597 to 0.91989, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.9496 - mean_absolute_error: 0.6202 - val_loss: 0.9199 - val_mean_absolute_error: 0.6074\n",
      "Epoch 26/200\n",
      "\u001b[1m230/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.9323 - mean_absolute_error: 0.6218\n",
      "Epoch 26: val_loss improved from 0.91989 to 0.91243, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.9334 - mean_absolute_error: 0.6209 - val_loss: 0.9124 - val_mean_absolute_error: 0.6109\n",
      "Epoch 27/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.8632 - mean_absolute_error: 0.6049\n",
      "Epoch 27: val_loss did not improve from 0.91243\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.8733 - mean_absolute_error: 0.6064 - val_loss: 0.9247 - val_mean_absolute_error: 0.6329\n",
      "Epoch 28/200\n",
      "\u001b[1m250/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.9694 - mean_absolute_error: 0.6215\n",
      "Epoch 28: val_loss improved from 0.91243 to 0.90523, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9638 - mean_absolute_error: 0.6209 - val_loss: 0.9052 - val_mean_absolute_error: 0.6016\n",
      "Epoch 29/200\n",
      "\u001b[1m224/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.8961 - mean_absolute_error: 0.6048\n",
      "Epoch 29: val_loss improved from 0.90523 to 0.90189, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9018 - mean_absolute_error: 0.6061 - val_loss: 0.9019 - val_mean_absolute_error: 0.6044\n",
      "Epoch 30/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.8866 - mean_absolute_error: 0.6075\n",
      "Epoch 30: val_loss did not improve from 0.90189\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.8960 - mean_absolute_error: 0.6091 - val_loss: 0.9035 - val_mean_absolute_error: 0.6037\n",
      "Epoch 31/200\n",
      "\u001b[1m224/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.9207 - mean_absolute_error: 0.6111\n",
      "Epoch 31: val_loss did not improve from 0.90189\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.9215 - mean_absolute_error: 0.6116 - val_loss: 0.9120 - val_mean_absolute_error: 0.6027\n",
      "Epoch 32/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 0.9346 - mean_absolute_error: 0.6147\n",
      "Epoch 32: val_loss did not improve from 0.90189\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.9325 - mean_absolute_error: 0.6143 - val_loss: 0.9046 - val_mean_absolute_error: 0.6158\n",
      "Epoch 33/200\n",
      "\u001b[1m230/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.9272 - mean_absolute_error: 0.6235\n",
      "Epoch 33: val_loss improved from 0.90189 to 0.89677, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9259 - mean_absolute_error: 0.6211 - val_loss: 0.8968 - val_mean_absolute_error: 0.6116\n",
      "Epoch 34/200\n",
      "\u001b[1m246/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.9165 - mean_absolute_error: 0.6177\n",
      "Epoch 34: val_loss improved from 0.89677 to 0.89651, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.9146 - mean_absolute_error: 0.6162 - val_loss: 0.8965 - val_mean_absolute_error: 0.6055\n",
      "Epoch 35/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.8846 - mean_absolute_error: 0.6029\n",
      "Epoch 35: val_loss did not improve from 0.89651\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.8905 - mean_absolute_error: 0.6043 - val_loss: 0.8989 - val_mean_absolute_error: 0.6094\n",
      "Epoch 36/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.9074 - mean_absolute_error: 0.6177\n",
      "Epoch 36: val_loss improved from 0.89651 to 0.89149, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.9071 - mean_absolute_error: 0.6160 - val_loss: 0.8915 - val_mean_absolute_error: 0.6045\n",
      "Epoch 37/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.8570 - mean_absolute_error: 0.5979\n",
      "Epoch 37: val_loss did not improve from 0.89149\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.8640 - mean_absolute_error: 0.5997 - val_loss: 0.8983 - val_mean_absolute_error: 0.6172\n",
      "Epoch 38/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.9416 - mean_absolute_error: 0.6194\n",
      "Epoch 38: val_loss improved from 0.89149 to 0.88592, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.9381 - mean_absolute_error: 0.6182 - val_loss: 0.8859 - val_mean_absolute_error: 0.6017\n",
      "Epoch 39/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 0.8381 - mean_absolute_error: 0.5897\n",
      "Epoch 39: val_loss improved from 0.88592 to 0.88481, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8513 - mean_absolute_error: 0.5932 - val_loss: 0.8848 - val_mean_absolute_error: 0.6084\n",
      "Epoch 40/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.9258 - mean_absolute_error: 0.6203\n",
      "Epoch 40: val_loss did not improve from 0.88481\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.9213 - mean_absolute_error: 0.6181 - val_loss: 0.8866 - val_mean_absolute_error: 0.6031\n",
      "Epoch 41/200\n",
      "\u001b[1m231/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.8901 - mean_absolute_error: 0.5970\n",
      "Epoch 41: val_loss did not improve from 0.88481\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.8912 - mean_absolute_error: 0.5987 - val_loss: 0.8956 - val_mean_absolute_error: 0.6262\n",
      "Epoch 42/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.9889 - mean_absolute_error: 0.6279\n",
      "Epoch 42: val_loss improved from 0.88481 to 0.88220, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.9759 - mean_absolute_error: 0.6251 - val_loss: 0.8822 - val_mean_absolute_error: 0.5966\n",
      "Epoch 43/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.9614 - mean_absolute_error: 0.6102\n",
      "Epoch 43: val_loss improved from 0.88220 to 0.87623, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.9527 - mean_absolute_error: 0.6098 - val_loss: 0.8762 - val_mean_absolute_error: 0.5960\n",
      "Epoch 44/200\n",
      "\u001b[1m248/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.9445 - mean_absolute_error: 0.6144\n",
      "Epoch 44: val_loss did not improve from 0.87623\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.9379 - mean_absolute_error: 0.6132 - val_loss: 0.8782 - val_mean_absolute_error: 0.5957\n",
      "Epoch 45/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.8605 - mean_absolute_error: 0.5968\n",
      "Epoch 45: val_loss did not improve from 0.87623\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.8659 - mean_absolute_error: 0.5982 - val_loss: 0.8771 - val_mean_absolute_error: 0.5970\n",
      "Epoch 46/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.8933 - mean_absolute_error: 0.6006\n",
      "Epoch 46: val_loss improved from 0.87623 to 0.87290, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8941 - mean_absolute_error: 0.6017 - val_loss: 0.8729 - val_mean_absolute_error: 0.5981\n",
      "Epoch 47/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.8694 - mean_absolute_error: 0.6025\n",
      "Epoch 47: val_loss did not improve from 0.87290\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - loss: 0.8728 - mean_absolute_error: 0.6029 - val_loss: 0.8774 - val_mean_absolute_error: 0.6074\n",
      "Epoch 48/200\n",
      "\u001b[1m229/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.8001 - mean_absolute_error: 0.5880\n",
      "Epoch 48: val_loss did not improve from 0.87290\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.8176 - mean_absolute_error: 0.5909 - val_loss: 0.8738 - val_mean_absolute_error: 0.6111\n",
      "Epoch 49/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.9497 - mean_absolute_error: 0.6234\n",
      "Epoch 49: val_loss improved from 0.87290 to 0.86896, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.9392 - mean_absolute_error: 0.6203 - val_loss: 0.8690 - val_mean_absolute_error: 0.5935\n",
      "Epoch 50/200\n",
      "\u001b[1m246/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.8912 - mean_absolute_error: 0.6001\n",
      "Epoch 50: val_loss did not improve from 0.86896\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.8885 - mean_absolute_error: 0.6005 - val_loss: 0.8839 - val_mean_absolute_error: 0.6064\n",
      "Epoch 51/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.8947 - mean_absolute_error: 0.6053\n",
      "Epoch 51: val_loss did not improve from 0.86896\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.8912 - mean_absolute_error: 0.6047 - val_loss: 0.8695 - val_mean_absolute_error: 0.5950\n",
      "Epoch 52/200\n",
      "\u001b[1m232/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.9095 - mean_absolute_error: 0.6129\n",
      "Epoch 52: val_loss did not improve from 0.86896\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.9038 - mean_absolute_error: 0.6109 - val_loss: 0.8700 - val_mean_absolute_error: 0.6073\n",
      "Epoch 53/200\n",
      "\u001b[1m230/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.9123 - mean_absolute_error: 0.6159\n",
      "Epoch 53: val_loss improved from 0.86896 to 0.86739, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9047 - mean_absolute_error: 0.6132 - val_loss: 0.8674 - val_mean_absolute_error: 0.5938\n",
      "Epoch 54/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.8621 - mean_absolute_error: 0.6022\n",
      "Epoch 54: val_loss improved from 0.86739 to 0.86198, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.8627 - mean_absolute_error: 0.6016 - val_loss: 0.8620 - val_mean_absolute_error: 0.5936\n",
      "Epoch 55/200\n",
      "\u001b[1m230/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.8261 - mean_absolute_error: 0.5892\n",
      "Epoch 55: val_loss did not improve from 0.86198\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.8371 - mean_absolute_error: 0.5917 - val_loss: 0.8693 - val_mean_absolute_error: 0.6004\n",
      "Epoch 56/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.8716 - mean_absolute_error: 0.5970\n",
      "Epoch 56: val_loss did not improve from 0.86198\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.8741 - mean_absolute_error: 0.5985 - val_loss: 0.8625 - val_mean_absolute_error: 0.5968\n",
      "Epoch 57/200\n",
      "\u001b[1m230/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.8358 - mean_absolute_error: 0.5882\n",
      "Epoch 57: val_loss did not improve from 0.86198\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.8420 - mean_absolute_error: 0.5905 - val_loss: 0.8675 - val_mean_absolute_error: 0.6039\n",
      "Epoch 58/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.8403 - mean_absolute_error: 0.5944\n",
      "Epoch 58: val_loss did not improve from 0.86198\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.8471 - mean_absolute_error: 0.5957 - val_loss: 0.8693 - val_mean_absolute_error: 0.6051\n",
      "Epoch 59/200\n",
      "\u001b[1m226/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.8519 - mean_absolute_error: 0.6005\n",
      "Epoch 59: val_loss improved from 0.86198 to 0.85451, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8584 - mean_absolute_error: 0.6012 - val_loss: 0.8545 - val_mean_absolute_error: 0.5853\n",
      "Epoch 60/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.8212 - mean_absolute_error: 0.5873\n",
      "Epoch 60: val_loss did not improve from 0.85451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.8304 - mean_absolute_error: 0.5893 - val_loss: 0.8645 - val_mean_absolute_error: 0.5997\n",
      "Epoch 61/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.8278 - mean_absolute_error: 0.5909\n",
      "Epoch 61: val_loss did not improve from 0.85451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.8365 - mean_absolute_error: 0.5930 - val_loss: 0.8555 - val_mean_absolute_error: 0.5915\n",
      "Epoch 62/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.8700 - mean_absolute_error: 0.5977\n",
      "Epoch 62: val_loss did not improve from 0.85451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.8683 - mean_absolute_error: 0.5978 - val_loss: 0.8590 - val_mean_absolute_error: 0.5989\n",
      "Epoch 63/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.9221 - mean_absolute_error: 0.6120\n",
      "Epoch 63: val_loss did not improve from 0.85451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.9139 - mean_absolute_error: 0.6107 - val_loss: 0.8646 - val_mean_absolute_error: 0.5932\n",
      "Epoch 64/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.9050 - mean_absolute_error: 0.6059\n",
      "Epoch 64: val_loss did not improve from 0.85451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.8995 - mean_absolute_error: 0.6049 - val_loss: 0.8627 - val_mean_absolute_error: 0.5919\n",
      "Epoch 65/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.8624 - mean_absolute_error: 0.5926\n",
      "Epoch 65: val_loss improved from 0.85451 to 0.85374, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.8633 - mean_absolute_error: 0.5937 - val_loss: 0.8537 - val_mean_absolute_error: 0.5882\n",
      "Epoch 66/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.8484 - mean_absolute_error: 0.5959\n",
      "Epoch 66: val_loss improved from 0.85374 to 0.84696, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8512 - mean_absolute_error: 0.5957 - val_loss: 0.8470 - val_mean_absolute_error: 0.6004\n",
      "Epoch 67/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.8473 - mean_absolute_error: 0.5999\n",
      "Epoch 67: val_loss did not improve from 0.84696\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.8479 - mean_absolute_error: 0.5991 - val_loss: 0.8518 - val_mean_absolute_error: 0.5969\n",
      "Epoch 68/200\n",
      "\u001b[1m226/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.8441 - mean_absolute_error: 0.5987\n",
      "Epoch 68: val_loss improved from 0.84696 to 0.84671, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8488 - mean_absolute_error: 0.5992 - val_loss: 0.8467 - val_mean_absolute_error: 0.5849\n",
      "Epoch 69/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.8628 - mean_absolute_error: 0.5939\n",
      "Epoch 69: val_loss improved from 0.84671 to 0.84197, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.8639 - mean_absolute_error: 0.5947 - val_loss: 0.8420 - val_mean_absolute_error: 0.5894\n",
      "Epoch 70/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.8881 - mean_absolute_error: 0.5912\n",
      "Epoch 70: val_loss did not improve from 0.84197\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.8850 - mean_absolute_error: 0.5930 - val_loss: 0.8466 - val_mean_absolute_error: 0.5896\n",
      "Epoch 71/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.9549 - mean_absolute_error: 0.6291\n",
      "Epoch 71: val_loss did not improve from 0.84197\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.9395 - mean_absolute_error: 0.6239 - val_loss: 0.8422 - val_mean_absolute_error: 0.5898\n",
      "Epoch 72/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.9017 - mean_absolute_error: 0.6115\n",
      "Epoch 72: val_loss improved from 0.84197 to 0.84144, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.8940 - mean_absolute_error: 0.6088 - val_loss: 0.8414 - val_mean_absolute_error: 0.5953\n",
      "Epoch 73/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.8018 - mean_absolute_error: 0.5848\n",
      "Epoch 73: val_loss did not improve from 0.84144\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.8121 - mean_absolute_error: 0.5874 - val_loss: 0.8422 - val_mean_absolute_error: 0.5903\n",
      "Epoch 74/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 0.8050 - mean_absolute_error: 0.5940\n",
      "Epoch 74: val_loss did not improve from 0.84144\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.8141 - mean_absolute_error: 0.5944 - val_loss: 0.8443 - val_mean_absolute_error: 0.5880\n",
      "Epoch 75/200\n",
      "\u001b[1m223/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.8790 - mean_absolute_error: 0.5957\n",
      "Epoch 75: val_loss did not improve from 0.84144\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.8754 - mean_absolute_error: 0.5961 - val_loss: 0.8529 - val_mean_absolute_error: 0.6010\n",
      "Epoch 76/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.8706 - mean_absolute_error: 0.5964\n",
      "Epoch 76: val_loss did not improve from 0.84144\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.8665 - mean_absolute_error: 0.5961 - val_loss: 0.8500 - val_mean_absolute_error: 0.5906\n",
      "Epoch 77/200\n",
      "\u001b[1m232/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.7790 - mean_absolute_error: 0.5806\n",
      "Epoch 77: val_loss did not improve from 0.84144\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.7942 - mean_absolute_error: 0.5837 - val_loss: 0.8443 - val_mean_absolute_error: 0.5890\n",
      "Epoch 78/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.8733 - mean_absolute_error: 0.5938\n",
      "Epoch 78: val_loss improved from 0.84144 to 0.84084, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.8706 - mean_absolute_error: 0.5945 - val_loss: 0.8408 - val_mean_absolute_error: 0.5913\n",
      "Epoch 79/200\n",
      "\u001b[1m245/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.8366 - mean_absolute_error: 0.5851\n",
      "Epoch 79: val_loss did not improve from 0.84084\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.8394 - mean_absolute_error: 0.5866 - val_loss: 0.8414 - val_mean_absolute_error: 0.5921\n",
      "Epoch 80/200\n",
      "\u001b[1m256/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.8689 - mean_absolute_error: 0.5971\n",
      "Epoch 80: val_loss improved from 0.84084 to 0.83267, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.8676 - mean_absolute_error: 0.5971 - val_loss: 0.8327 - val_mean_absolute_error: 0.5852\n",
      "Epoch 81/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.7406 - mean_absolute_error: 0.5681\n",
      "Epoch 81: val_loss did not improve from 0.83267\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.7566 - mean_absolute_error: 0.5718 - val_loss: 0.8402 - val_mean_absolute_error: 0.5895\n",
      "Epoch 82/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 0.8653 - mean_absolute_error: 0.5970\n",
      "Epoch 82: val_loss did not improve from 0.83267\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.8621 - mean_absolute_error: 0.5963 - val_loss: 0.8329 - val_mean_absolute_error: 0.5925\n",
      "Epoch 83/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.8475 - mean_absolute_error: 0.5986\n",
      "Epoch 83: val_loss did not improve from 0.83267\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.8477 - mean_absolute_error: 0.5980 - val_loss: 0.8372 - val_mean_absolute_error: 0.5950\n",
      "Epoch 84/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.8667 - mean_absolute_error: 0.6012\n",
      "Epoch 84: val_loss did not improve from 0.83267\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.8633 - mean_absolute_error: 0.6004 - val_loss: 0.8389 - val_mean_absolute_error: 0.5934\n",
      "Epoch 85/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.9101 - mean_absolute_error: 0.6043\n",
      "Epoch 85: val_loss did not improve from 0.83267\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.9002 - mean_absolute_error: 0.6027 - val_loss: 0.8415 - val_mean_absolute_error: 0.5936\n",
      "Epoch 86/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.8243 - mean_absolute_error: 0.5888\n",
      "Epoch 86: val_loss did not improve from 0.83267\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.8300 - mean_absolute_error: 0.5903 - val_loss: 0.8336 - val_mean_absolute_error: 0.5863\n",
      "Epoch 87/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.8690 - mean_absolute_error: 0.5939\n",
      "Epoch 87: val_loss improved from 0.83267 to 0.82698, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.8644 - mean_absolute_error: 0.5936 - val_loss: 0.8270 - val_mean_absolute_error: 0.5879\n",
      "Epoch 88/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.8107 - mean_absolute_error: 0.5798\n",
      "Epoch 88: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.8160 - mean_absolute_error: 0.5821 - val_loss: 0.8375 - val_mean_absolute_error: 0.5935\n",
      "Epoch 89/200\n",
      "\u001b[1m220/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.8338 - mean_absolute_error: 0.5902\n",
      "Epoch 89: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.8359 - mean_absolute_error: 0.5913 - val_loss: 0.8313 - val_mean_absolute_error: 0.5950\n",
      "Epoch 90/200\n",
      "\u001b[1m212/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.8129 - mean_absolute_error: 0.5833\n",
      "Epoch 90: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.8222 - mean_absolute_error: 0.5862 - val_loss: 0.8357 - val_mean_absolute_error: 0.6005\n",
      "Epoch 91/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.8378 - mean_absolute_error: 0.5969\n",
      "Epoch 91: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.8375 - mean_absolute_error: 0.5960 - val_loss: 0.8369 - val_mean_absolute_error: 0.5931\n",
      "Epoch 92/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.7570 - mean_absolute_error: 0.5819\n",
      "Epoch 92: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.7729 - mean_absolute_error: 0.5848 - val_loss: 0.8374 - val_mean_absolute_error: 0.5982\n",
      "Epoch 93/200\n",
      "\u001b[1m227/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.7849 - mean_absolute_error: 0.5821\n",
      "Epoch 93: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.7940 - mean_absolute_error: 0.5838 - val_loss: 0.8279 - val_mean_absolute_error: 0.5864\n",
      "Epoch 94/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.9014 - mean_absolute_error: 0.6068\n",
      "Epoch 94: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.8899 - mean_absolute_error: 0.6042 - val_loss: 0.8299 - val_mean_absolute_error: 0.5940\n",
      "Epoch 95/200\n",
      "\u001b[1m246/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.8195 - mean_absolute_error: 0.5909\n",
      "Epoch 95: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.8214 - mean_absolute_error: 0.5910 - val_loss: 0.8358 - val_mean_absolute_error: 0.6031\n",
      "Epoch 96/200\n",
      "\u001b[1m246/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.8304 - mean_absolute_error: 0.5873\n",
      "Epoch 96: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.8327 - mean_absolute_error: 0.5885 - val_loss: 0.8431 - val_mean_absolute_error: 0.5878\n",
      "Epoch 97/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.8383 - mean_absolute_error: 0.5911\n",
      "Epoch 97: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.8380 - mean_absolute_error: 0.5913 - val_loss: 0.8291 - val_mean_absolute_error: 0.5853\n",
      "Epoch 98/200\n",
      "\u001b[1m221/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.8540 - mean_absolute_error: 0.5903\n",
      "Epoch 98: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.8534 - mean_absolute_error: 0.5908 - val_loss: 0.8368 - val_mean_absolute_error: 0.6015\n",
      "Epoch 99/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.7897 - mean_absolute_error: 0.5810\n",
      "Epoch 99: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.8005 - mean_absolute_error: 0.5838 - val_loss: 0.8315 - val_mean_absolute_error: 0.5823\n",
      "Epoch 100/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.8308 - mean_absolute_error: 0.5912\n",
      "Epoch 100: val_loss did not improve from 0.82698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.8323 - mean_absolute_error: 0.5915 - val_loss: 0.8338 - val_mean_absolute_error: 0.5862\n",
      "Epoch 101/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.8020 - mean_absolute_error: 0.5809\n",
      "Epoch 101: val_loss improved from 0.82698 to 0.82617, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.8099 - mean_absolute_error: 0.5828 - val_loss: 0.8262 - val_mean_absolute_error: 0.5895\n",
      "Epoch 102/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.8426 - mean_absolute_error: 0.5933\n",
      "Epoch 102: val_loss did not improve from 0.82617\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.8412 - mean_absolute_error: 0.5933 - val_loss: 0.8583 - val_mean_absolute_error: 0.6163\n",
      "Epoch 103/200\n",
      "\u001b[1m220/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.8056 - mean_absolute_error: 0.5914\n",
      "Epoch 103: val_loss did not improve from 0.82617\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.8094 - mean_absolute_error: 0.5916 - val_loss: 0.8348 - val_mean_absolute_error: 0.6062\n",
      "Epoch 104/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.9303 - mean_absolute_error: 0.6193\n",
      "Epoch 104: val_loss did not improve from 0.82617\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.9145 - mean_absolute_error: 0.6150 - val_loss: 0.8516 - val_mean_absolute_error: 0.6023\n",
      "Epoch 105/200\n",
      "\u001b[1m221/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.8098 - mean_absolute_error: 0.5823\n",
      "Epoch 105: val_loss did not improve from 0.82617\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.8158 - mean_absolute_error: 0.5842 - val_loss: 0.8293 - val_mean_absolute_error: 0.5908\n",
      "Epoch 106/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.7637 - mean_absolute_error: 0.5750\n",
      "Epoch 106: val_loss improved from 0.82617 to 0.82373, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7742 - mean_absolute_error: 0.5775 - val_loss: 0.8237 - val_mean_absolute_error: 0.5850\n",
      "Epoch 107/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.7990 - mean_absolute_error: 0.5869\n",
      "Epoch 107: val_loss did not improve from 0.82373\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.8020 - mean_absolute_error: 0.5866 - val_loss: 0.8366 - val_mean_absolute_error: 0.6130\n",
      "Epoch 108/200\n",
      "\u001b[1m225/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.8710 - mean_absolute_error: 0.6022\n",
      "Epoch 108: val_loss improved from 0.82373 to 0.82271, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8610 - mean_absolute_error: 0.5995 - val_loss: 0.8227 - val_mean_absolute_error: 0.5885\n",
      "Epoch 109/200\n",
      "\u001b[1m221/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.8314 - mean_absolute_error: 0.5913\n",
      "Epoch 109: val_loss did not improve from 0.82271\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.8326 - mean_absolute_error: 0.5911 - val_loss: 0.8250 - val_mean_absolute_error: 0.5856\n",
      "Epoch 110/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.8000 - mean_absolute_error: 0.5770\n",
      "Epoch 110: val_loss did not improve from 0.82271\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.8054 - mean_absolute_error: 0.5793 - val_loss: 0.8244 - val_mean_absolute_error: 0.5941\n",
      "Epoch 111/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 0.8668 - mean_absolute_error: 0.5994\n",
      "Epoch 111: val_loss improved from 0.82271 to 0.82053, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.8632 - mean_absolute_error: 0.5988 - val_loss: 0.8205 - val_mean_absolute_error: 0.5856\n",
      "Epoch 112/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.8605 - mean_absolute_error: 0.5957\n",
      "Epoch 112: val_loss did not improve from 0.82053\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.8564 - mean_absolute_error: 0.5951 - val_loss: 0.8251 - val_mean_absolute_error: 0.5840\n",
      "Epoch 113/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.8013 - mean_absolute_error: 0.5803\n",
      "Epoch 113: val_loss did not improve from 0.82053\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.8060 - mean_absolute_error: 0.5820 - val_loss: 0.8239 - val_mean_absolute_error: 0.5895\n",
      "Epoch 114/200\n",
      "\u001b[1m245/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.8203 - mean_absolute_error: 0.5909\n",
      "Epoch 114: val_loss did not improve from 0.82053\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.8220 - mean_absolute_error: 0.5914 - val_loss: 0.8435 - val_mean_absolute_error: 0.5976\n",
      "Epoch 115/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.7921 - mean_absolute_error: 0.5775\n",
      "Epoch 115: val_loss did not improve from 0.82053\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.7972 - mean_absolute_error: 0.5792 - val_loss: 0.8300 - val_mean_absolute_error: 0.6038\n",
      "Epoch 116/200\n",
      "\u001b[1m250/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 0.8227 - mean_absolute_error: 0.5936\n",
      "Epoch 116: val_loss improved from 0.82053 to 0.81760, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.8235 - mean_absolute_error: 0.5932 - val_loss: 0.8176 - val_mean_absolute_error: 0.5875\n",
      "Epoch 117/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.7846 - mean_absolute_error: 0.5789\n",
      "Epoch 117: val_loss did not improve from 0.81760\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.7907 - mean_absolute_error: 0.5804 - val_loss: 0.8396 - val_mean_absolute_error: 0.6232\n",
      "Epoch 118/200\n",
      "\u001b[1m247/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.7925 - mean_absolute_error: 0.5827\n",
      "Epoch 118: val_loss improved from 0.81760 to 0.81470, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.7977 - mean_absolute_error: 0.5839 - val_loss: 0.8147 - val_mean_absolute_error: 0.5862\n",
      "Epoch 119/200\n",
      "\u001b[1m229/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.7691 - mean_absolute_error: 0.5801\n",
      "Epoch 119: val_loss did not improve from 0.81470\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.7815 - mean_absolute_error: 0.5820 - val_loss: 0.8243 - val_mean_absolute_error: 0.5983\n",
      "Epoch 120/200\n",
      "\u001b[1m215/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.8553 - mean_absolute_error: 0.5996\n",
      "Epoch 120: val_loss did not improve from 0.81470\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.8467 - mean_absolute_error: 0.5965 - val_loss: 0.8358 - val_mean_absolute_error: 0.6126\n",
      "Epoch 121/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.8341 - mean_absolute_error: 0.5969\n",
      "Epoch 121: val_loss did not improve from 0.81470\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.8330 - mean_absolute_error: 0.5962 - val_loss: 0.8165 - val_mean_absolute_error: 0.5916\n",
      "Epoch 122/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 0.8964 - mean_absolute_error: 0.6093\n",
      "Epoch 122: val_loss did not improve from 0.81470\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.8862 - mean_absolute_error: 0.6062 - val_loss: 0.8265 - val_mean_absolute_error: 0.5922\n",
      "Epoch 123/200\n",
      "\u001b[1m231/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.9286 - mean_absolute_error: 0.6164\n",
      "Epoch 123: val_loss did not improve from 0.81470\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.9103 - mean_absolute_error: 0.6124 - val_loss: 0.8150 - val_mean_absolute_error: 0.5834\n",
      "Epoch 124/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.8668 - mean_absolute_error: 0.6015\n",
      "Epoch 124: val_loss did not improve from 0.81470\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.8603 - mean_absolute_error: 0.5996 - val_loss: 0.8196 - val_mean_absolute_error: 0.5991\n",
      "Epoch 125/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.8806 - mean_absolute_error: 0.6022\n",
      "Epoch 125: val_loss did not improve from 0.81470\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.8732 - mean_absolute_error: 0.6006 - val_loss: 0.8225 - val_mean_absolute_error: 0.6009\n",
      "Epoch 126/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.8366 - mean_absolute_error: 0.5918\n",
      "Epoch 126: val_loss improved from 0.81470 to 0.81230, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8330 - mean_absolute_error: 0.5909 - val_loss: 0.8123 - val_mean_absolute_error: 0.5879\n",
      "Epoch 127/200\n",
      "\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.7603 - mean_absolute_error: 0.5830\n",
      "Epoch 127: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.7607 - mean_absolute_error: 0.5830 - val_loss: 0.8229 - val_mean_absolute_error: 0.5905\n",
      "Epoch 128/200\n",
      "\u001b[1m225/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.8421 - mean_absolute_error: 0.5912\n",
      "Epoch 128: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.8358 - mean_absolute_error: 0.5903 - val_loss: 0.8202 - val_mean_absolute_error: 0.5993\n",
      "Epoch 129/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.8268 - mean_absolute_error: 0.5907\n",
      "Epoch 129: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.8259 - mean_absolute_error: 0.5907 - val_loss: 0.8252 - val_mean_absolute_error: 0.6057\n",
      "Epoch 130/200\n",
      "\u001b[1m227/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.8292 - mean_absolute_error: 0.5876\n",
      "Epoch 130: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.8277 - mean_absolute_error: 0.5887 - val_loss: 0.8144 - val_mean_absolute_error: 0.5904\n",
      "Epoch 131/200\n",
      "\u001b[1m229/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.8663 - mean_absolute_error: 0.5994\n",
      "Epoch 131: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.8586 - mean_absolute_error: 0.5975 - val_loss: 0.8280 - val_mean_absolute_error: 0.5961\n",
      "Epoch 132/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.7607 - mean_absolute_error: 0.5789\n",
      "Epoch 132: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.7734 - mean_absolute_error: 0.5807 - val_loss: 0.8124 - val_mean_absolute_error: 0.5852\n",
      "Epoch 133/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.8309 - mean_absolute_error: 0.5906\n",
      "Epoch 133: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.8276 - mean_absolute_error: 0.5897 - val_loss: 0.8288 - val_mean_absolute_error: 0.6161\n",
      "Epoch 134/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.8117 - mean_absolute_error: 0.5865\n",
      "Epoch 134: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.8138 - mean_absolute_error: 0.5865 - val_loss: 0.8136 - val_mean_absolute_error: 0.5897\n",
      "Epoch 135/200\n",
      "\u001b[1m229/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.8571 - mean_absolute_error: 0.5997\n",
      "Epoch 135: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.8517 - mean_absolute_error: 0.5983 - val_loss: 0.8142 - val_mean_absolute_error: 0.5938\n",
      "Epoch 136/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.7944 - mean_absolute_error: 0.5797\n",
      "Epoch 136: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.7948 - mean_absolute_error: 0.5798 - val_loss: 0.8164 - val_mean_absolute_error: 0.5980\n",
      "Epoch 137/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.7987 - mean_absolute_error: 0.5852\n",
      "Epoch 137: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.8022 - mean_absolute_error: 0.5857 - val_loss: 0.8144 - val_mean_absolute_error: 0.5944\n",
      "Epoch 138/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.8491 - mean_absolute_error: 0.5929\n",
      "Epoch 138: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.8442 - mean_absolute_error: 0.5925 - val_loss: 0.8136 - val_mean_absolute_error: 0.5902\n",
      "Epoch 139/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.8007 - mean_absolute_error: 0.5810\n",
      "Epoch 139: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.8040 - mean_absolute_error: 0.5822 - val_loss: 0.8335 - val_mean_absolute_error: 0.6073\n",
      "Epoch 140/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.8263 - mean_absolute_error: 0.5979\n",
      "Epoch 140: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.8247 - mean_absolute_error: 0.5961 - val_loss: 0.8133 - val_mean_absolute_error: 0.5950\n",
      "Epoch 141/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.7885 - mean_absolute_error: 0.5791\n",
      "Epoch 141: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.7941 - mean_absolute_error: 0.5808 - val_loss: 0.8179 - val_mean_absolute_error: 0.5889\n",
      "Epoch 142/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.7707 - mean_absolute_error: 0.5657\n",
      "Epoch 142: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.7780 - mean_absolute_error: 0.5692 - val_loss: 0.8132 - val_mean_absolute_error: 0.5936\n",
      "Epoch 143/200\n",
      "\u001b[1m231/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.8247 - mean_absolute_error: 0.5888\n",
      "Epoch 143: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.8255 - mean_absolute_error: 0.5892 - val_loss: 0.8168 - val_mean_absolute_error: 0.5857\n",
      "Epoch 144/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.7807 - mean_absolute_error: 0.5724\n",
      "Epoch 144: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.7846 - mean_absolute_error: 0.5745 - val_loss: 0.8230 - val_mean_absolute_error: 0.6023\n",
      "Epoch 145/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.8507 - mean_absolute_error: 0.5978\n",
      "Epoch 145: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.8446 - mean_absolute_error: 0.5954 - val_loss: 0.8141 - val_mean_absolute_error: 0.5924\n",
      "Epoch 146/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.8588 - mean_absolute_error: 0.5939\n",
      "Epoch 146: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.8529 - mean_absolute_error: 0.5930 - val_loss: 0.8126 - val_mean_absolute_error: 0.5876\n",
      "Epoch 147/200\n",
      "\u001b[1m220/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.7535 - mean_absolute_error: 0.5740\n",
      "Epoch 147: val_loss did not improve from 0.81230\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.7723 - mean_absolute_error: 0.5787 - val_loss: 0.8137 - val_mean_absolute_error: 0.5827\n",
      "Epoch 148/200\n",
      "\u001b[1m232/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.8536 - mean_absolute_error: 0.6044\n",
      "Epoch 148: val_loss improved from 0.81230 to 0.80816, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8465 - mean_absolute_error: 0.6011 - val_loss: 0.8082 - val_mean_absolute_error: 0.5926\n",
      "Epoch 149/200\n",
      "\u001b[1m229/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.7785 - mean_absolute_error: 0.5778\n",
      "Epoch 149: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.7865 - mean_absolute_error: 0.5797 - val_loss: 0.8294 - val_mean_absolute_error: 0.6056\n",
      "Epoch 150/200\n",
      "\u001b[1m229/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.8065 - mean_absolute_error: 0.5845\n",
      "Epoch 150: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.8048 - mean_absolute_error: 0.5843 - val_loss: 0.8145 - val_mean_absolute_error: 0.5948\n",
      "Epoch 151/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.8332 - mean_absolute_error: 0.5882\n",
      "Epoch 151: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.8295 - mean_absolute_error: 0.5877 - val_loss: 0.8164 - val_mean_absolute_error: 0.5982\n",
      "Epoch 152/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.7953 - mean_absolute_error: 0.5867\n",
      "Epoch 152: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.7960 - mean_absolute_error: 0.5864 - val_loss: 0.8120 - val_mean_absolute_error: 0.5949\n",
      "Epoch 153/200\n",
      "\u001b[1m236/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.8454 - mean_absolute_error: 0.5894\n",
      "Epoch 153: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.8409 - mean_absolute_error: 0.5895 - val_loss: 0.8120 - val_mean_absolute_error: 0.5859\n",
      "Epoch 154/200\n",
      "\u001b[1m232/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.7726 - mean_absolute_error: 0.5762\n",
      "Epoch 154: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.7787 - mean_absolute_error: 0.5780 - val_loss: 0.8155 - val_mean_absolute_error: 0.6016\n",
      "Epoch 155/200\n",
      "\u001b[1m245/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.8232 - mean_absolute_error: 0.5918\n",
      "Epoch 155: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.8222 - mean_absolute_error: 0.5911 - val_loss: 0.8227 - val_mean_absolute_error: 0.6100\n",
      "Epoch 156/200\n",
      "\u001b[1m244/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.7827 - mean_absolute_error: 0.5757\n",
      "Epoch 156: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.7869 - mean_absolute_error: 0.5771 - val_loss: 0.8118 - val_mean_absolute_error: 0.5933\n",
      "Epoch 157/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.8536 - mean_absolute_error: 0.5938\n",
      "Epoch 157: val_loss did not improve from 0.80816\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.8445 - mean_absolute_error: 0.5922 - val_loss: 0.8169 - val_mean_absolute_error: 0.5963\n",
      "Epoch 158/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.8245 - mean_absolute_error: 0.5959\n",
      "Epoch 158: val_loss improved from 0.80816 to 0.80488, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.8233 - mean_absolute_error: 0.5943 - val_loss: 0.8049 - val_mean_absolute_error: 0.5850\n",
      "Epoch 159/200\n",
      "\u001b[1m245/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.7883 - mean_absolute_error: 0.5842\n",
      "Epoch 159: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.7920 - mean_absolute_error: 0.5844 - val_loss: 0.8114 - val_mean_absolute_error: 0.5924\n",
      "Epoch 160/200\n",
      "\u001b[1m247/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.8205 - mean_absolute_error: 0.5918\n",
      "Epoch 160: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.8172 - mean_absolute_error: 0.5908 - val_loss: 0.8187 - val_mean_absolute_error: 0.5981\n",
      "Epoch 161/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.7902 - mean_absolute_error: 0.5853\n",
      "Epoch 161: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.7951 - mean_absolute_error: 0.5860 - val_loss: 0.8196 - val_mean_absolute_error: 0.5953\n",
      "Epoch 162/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.7832 - mean_absolute_error: 0.5755\n",
      "Epoch 162: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.7876 - mean_absolute_error: 0.5774 - val_loss: 0.8233 - val_mean_absolute_error: 0.5903\n",
      "Epoch 163/200\n",
      "\u001b[1m243/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.7907 - mean_absolute_error: 0.5864\n",
      "Epoch 163: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.7913 - mean_absolute_error: 0.5858 - val_loss: 0.8253 - val_mean_absolute_error: 0.6167\n",
      "Epoch 164/200\n",
      "\u001b[1m248/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.8206 - mean_absolute_error: 0.5974\n",
      "Epoch 164: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.8198 - mean_absolute_error: 0.5965 - val_loss: 0.8111 - val_mean_absolute_error: 0.5992\n",
      "Epoch 165/200\n",
      "\u001b[1m242/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 0.8321 - mean_absolute_error: 0.6036\n",
      "Epoch 165: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.8277 - mean_absolute_error: 0.6005 - val_loss: 0.8074 - val_mean_absolute_error: 0.5962\n",
      "Epoch 166/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.8404 - mean_absolute_error: 0.5931\n",
      "Epoch 166: val_loss did not improve from 0.80488\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.8356 - mean_absolute_error: 0.5920 - val_loss: 0.8091 - val_mean_absolute_error: 0.5830\n",
      "Epoch 167/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.7696 - mean_absolute_error: 0.5691\n",
      "Epoch 167: val_loss improved from 0.80488 to 0.80451, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.7758 - mean_absolute_error: 0.5713 - val_loss: 0.8045 - val_mean_absolute_error: 0.5884\n",
      "Epoch 168/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.8159 - mean_absolute_error: 0.5876\n",
      "Epoch 168: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.8157 - mean_absolute_error: 0.5874 - val_loss: 0.8106 - val_mean_absolute_error: 0.5936\n",
      "Epoch 169/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.8501 - mean_absolute_error: 0.5977\n",
      "Epoch 169: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.8454 - mean_absolute_error: 0.5964 - val_loss: 0.8131 - val_mean_absolute_error: 0.5917\n",
      "Epoch 170/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.7810 - mean_absolute_error: 0.5781\n",
      "Epoch 170: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.7855 - mean_absolute_error: 0.5789 - val_loss: 0.8066 - val_mean_absolute_error: 0.5894\n",
      "Epoch 171/200\n",
      "\u001b[1m246/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.7725 - mean_absolute_error: 0.5735\n",
      "Epoch 171: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.7771 - mean_absolute_error: 0.5753 - val_loss: 0.8134 - val_mean_absolute_error: 0.5984\n",
      "Epoch 172/200\n",
      "\u001b[1m247/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.7903 - mean_absolute_error: 0.5836\n",
      "Epoch 172: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.7931 - mean_absolute_error: 0.5841 - val_loss: 0.8065 - val_mean_absolute_error: 0.5901\n",
      "Epoch 173/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.8247 - mean_absolute_error: 0.5847\n",
      "Epoch 173: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.8215 - mean_absolute_error: 0.5845 - val_loss: 0.8160 - val_mean_absolute_error: 0.6026\n",
      "Epoch 174/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.7678 - mean_absolute_error: 0.5788\n",
      "Epoch 174: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.7734 - mean_absolute_error: 0.5796 - val_loss: 0.8131 - val_mean_absolute_error: 0.6041\n",
      "Epoch 175/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.8263 - mean_absolute_error: 0.5869\n",
      "Epoch 175: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.8211 - mean_absolute_error: 0.5858 - val_loss: 0.8145 - val_mean_absolute_error: 0.5983\n",
      "Epoch 176/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.8446 - mean_absolute_error: 0.5944\n",
      "Epoch 176: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.8403 - mean_absolute_error: 0.5934 - val_loss: 0.8082 - val_mean_absolute_error: 0.5940\n",
      "Epoch 177/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.7738 - mean_absolute_error: 0.5788\n",
      "Epoch 177: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.7804 - mean_absolute_error: 0.5804 - val_loss: 0.8091 - val_mean_absolute_error: 0.5910\n",
      "Epoch 178/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.8012 - mean_absolute_error: 0.5909\n",
      "Epoch 178: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.8032 - mean_absolute_error: 0.5904 - val_loss: 0.8103 - val_mean_absolute_error: 0.5895\n",
      "Epoch 179/200\n",
      "\u001b[1m255/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 0.8532 - mean_absolute_error: 0.5901\n",
      "Epoch 179: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.8488 - mean_absolute_error: 0.5897 - val_loss: 0.8078 - val_mean_absolute_error: 0.5931\n",
      "Epoch 180/200\n",
      "\u001b[1m247/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.8492 - mean_absolute_error: 0.5995\n",
      "Epoch 180: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.8437 - mean_absolute_error: 0.5975 - val_loss: 0.8128 - val_mean_absolute_error: 0.5981\n",
      "Epoch 181/200\n",
      "\u001b[1m229/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.8338 - mean_absolute_error: 0.5910\n",
      "Epoch 181: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.8285 - mean_absolute_error: 0.5900 - val_loss: 0.8104 - val_mean_absolute_error: 0.5966\n",
      "Epoch 182/200\n",
      "\u001b[1m232/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.8028 - mean_absolute_error: 0.5802\n",
      "Epoch 182: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.8042 - mean_absolute_error: 0.5815 - val_loss: 0.8086 - val_mean_absolute_error: 0.5866\n",
      "Epoch 183/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.7663 - mean_absolute_error: 0.5701\n",
      "Epoch 183: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.7724 - mean_absolute_error: 0.5727 - val_loss: 0.8123 - val_mean_absolute_error: 0.5988\n",
      "Epoch 184/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.8013 - mean_absolute_error: 0.5786\n",
      "Epoch 184: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.8014 - mean_absolute_error: 0.5789 - val_loss: 0.8115 - val_mean_absolute_error: 0.6018\n",
      "Epoch 185/200\n",
      "\u001b[1m231/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.8673 - mean_absolute_error: 0.5973\n",
      "Epoch 185: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.8562 - mean_absolute_error: 0.5951 - val_loss: 0.8078 - val_mean_absolute_error: 0.5901\n",
      "Epoch 186/200\n",
      "\u001b[1m238/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.8716 - mean_absolute_error: 0.6151\n",
      "Epoch 186: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.8615 - mean_absolute_error: 0.6109 - val_loss: 0.8178 - val_mean_absolute_error: 0.5980\n",
      "Epoch 187/200\n",
      "\u001b[1m241/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.8370 - mean_absolute_error: 0.5920\n",
      "Epoch 187: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.8286 - mean_absolute_error: 0.5899 - val_loss: 0.8087 - val_mean_absolute_error: 0.6018\n",
      "Epoch 188/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.7557 - mean_absolute_error: 0.5775\n",
      "Epoch 188: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.7611 - mean_absolute_error: 0.5779 - val_loss: 0.8278 - val_mean_absolute_error: 0.6186\n",
      "Epoch 189/200\n",
      "\u001b[1m231/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.8191 - mean_absolute_error: 0.5859\n",
      "Epoch 189: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.8163 - mean_absolute_error: 0.5858 - val_loss: 0.8130 - val_mean_absolute_error: 0.6074\n",
      "Epoch 190/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.8213 - mean_absolute_error: 0.5903\n",
      "Epoch 190: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.8179 - mean_absolute_error: 0.5892 - val_loss: 0.8191 - val_mean_absolute_error: 0.6131\n",
      "Epoch 191/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.8446 - mean_absolute_error: 0.6044\n",
      "Epoch 191: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.8352 - mean_absolute_error: 0.6006 - val_loss: 0.8125 - val_mean_absolute_error: 0.5964\n",
      "Epoch 192/200\n",
      "\u001b[1m235/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 0.8592 - mean_absolute_error: 0.5906\n",
      "Epoch 192: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.8473 - mean_absolute_error: 0.5886 - val_loss: 0.8120 - val_mean_absolute_error: 0.5977\n",
      "Epoch 193/200\n",
      "\u001b[1m234/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.7759 - mean_absolute_error: 0.5803\n",
      "Epoch 193: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.7834 - mean_absolute_error: 0.5817 - val_loss: 0.8113 - val_mean_absolute_error: 0.5886\n",
      "Epoch 194/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.7257 - mean_absolute_error: 0.5658\n",
      "Epoch 194: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.7374 - mean_absolute_error: 0.5685 - val_loss: 0.8097 - val_mean_absolute_error: 0.5987\n",
      "Epoch 195/200\n",
      "\u001b[1m233/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.7951 - mean_absolute_error: 0.5846\n",
      "Epoch 195: val_loss did not improve from 0.80451\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.7963 - mean_absolute_error: 0.5847 - val_loss: 0.8146 - val_mean_absolute_error: 0.5935\n",
      "Epoch 196/200\n",
      "\u001b[1m239/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.8266 - mean_absolute_error: 0.5914\n",
      "Epoch 196: val_loss improved from 0.80451 to 0.80188, saving model to Results/Best_model/single_hidden_layer_ann_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.8221 - mean_absolute_error: 0.5901 - val_loss: 0.8019 - val_mean_absolute_error: 0.5906\n",
      "Epoch 197/200\n",
      "\u001b[1m230/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.8224 - mean_absolute_error: 0.5875\n",
      "Epoch 197: val_loss did not improve from 0.80188\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.8184 - mean_absolute_error: 0.5870 - val_loss: 0.8049 - val_mean_absolute_error: 0.5888\n",
      "Epoch 198/200\n",
      "\u001b[1m240/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.7839 - mean_absolute_error: 0.5772\n",
      "Epoch 198: val_loss did not improve from 0.80188\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.7886 - mean_absolute_error: 0.5786 - val_loss: 0.8099 - val_mean_absolute_error: 0.5891\n",
      "Epoch 199/200\n",
      "\u001b[1m247/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 0.7363 - mean_absolute_error: 0.5705\n",
      "Epoch 199: val_loss did not improve from 0.80188\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.7459 - mean_absolute_error: 0.5724 - val_loss: 0.8182 - val_mean_absolute_error: 0.6079\n",
      "Epoch 200/200\n",
      "\u001b[1m237/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.7767 - mean_absolute_error: 0.5808\n",
      "Epoch 200: val_loss did not improve from 0.80188\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.7805 - mean_absolute_error: 0.5813 - val_loss: 0.8166 - val_mean_absolute_error: 0.6109\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# Save the model\n",
    "#model.save('Results/Best_model/single_hidden_layer_ann_model.keras')\n",
    "\n",
    "# Save best model using checkpoint strategy\n",
    "filepath = 'Results/Best_model/single_hidden_layer_ann_model.keras'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto') #auto: The direction is automatically inferred from the name of the monitored quantity. For metrics like val_loss, where a decrease is better, it sets the mode to min. Conversely, for metrics like accuracy, where an increase is better, it sets the mode to max.\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# checkpoint: A variable that stores an instance of the ModelCheckpoint callback.\n",
    "# ModelCheckpoint: A callback provided by Keras that saves the model after every epoch.\n",
    "# filepath: The path where the model will be saved, as defined in the previous line.\n",
    "# monitor='val_loss': Specifies that the validation loss will be monitored. The model with the lowest validation loss will be saved.\n",
    "# verbose=1: Enables verbose output, so you will get messages in the console when the model is saved.\n",
    "# save_best_only=True: Ensures that only the best model (the one with the lowest validation loss) will be saved, not every model after each epoch.\n",
    "# mode='auto': Automatically determines whether to minimize or maximize the monitored quantity based on its name. For val_loss, a decrease is better, so it sets the mode to 'min'.\n",
    "# [checkpoint]: The list contains the checkpoint callback. This list can be passed to the model's fit method to enable the checkpointing during training.\n",
    "\n",
    "# compilation of model\n",
    "model.compile(optimizer=Adam(learning_rate = 0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# modelfitting\n",
    "history = model.fit(X_train_scaled, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d4c0a98b-e87a-4d8b-839a-362ba655f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step\n",
      "R2 score is: 0.83\n",
      "RMSE is: 0.88\n",
      "RRMSE is: 31.32%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the saved model\n",
    "Saved_model = load_model('Results/Best_model/single_hidden_layer_ann_model.keras')\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = Saved_model.predict(X_train_scaled)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rrmse = rmse/np.mean(y_test)*100\n",
    "print(f'R2 score is: {r2:.2f}')\n",
    "print(f'RMSE is: {rmse:.2f}')\n",
    "print(f'RRMSE is: {rrmse:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4f00d822-9d08-4aa2-8529-d89c0db11fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step\n",
      "R2 score is: 0.80\n",
      "RMSE is: 0.93\n",
      "RRMSE is: 33.22%\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics for testing data\n",
    "y_pred = Saved_model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rrmse = rmse/np.mean(y_test)*100\n",
    "print(f'R2 score is: {r2:.2f}')\n",
    "print(f'RMSE is: {rmse:.2f}')\n",
    "print(f'RRMSE is: {rrmse:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fb464d0f-7123-4e7e-89f3-70619be73cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc9ee8de550>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# visualize the training loss across different epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9aff2a",
   "metadata": {},
   "source": [
    " # 4.1. Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ae069cb-ad46-41aa-a382-543408059437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a2e1c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,889</span> (706.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m180,889\u001b[0m (706.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,513</span> (701.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,513\u001b[0m (701.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,376</span> (5.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,376\u001b[0m (5.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n",
    "# build a input layer\n",
    "from keras.layers import Input\n",
    "\n",
    "# retrieve the dimension of input features\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# define a specific seed to control random status and enforce model reproduceability\n",
    "np.random.seed(1)\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape = (num_features,))\n",
    "\n",
    "# create a hidden layer\n",
    "L1 = Dense (24, activation = 'relu') (input_layer)\n",
    "L2 = Dense (48, activation = 'relu') (L1)\n",
    "L3 = BatchNormalization() (L2)\n",
    "L4 = Dense (64, activation = 'relu') (L3)\n",
    "L5 = Dense (128, activation = 'relu') (L4)\n",
    "L6 = BatchNormalization() (L5)\n",
    "L7 = Dense (256, activation = 'relu') (L6)\n",
    "L8 = Dense (512, activation = 'relu') (L7)\n",
    "L9 = BatchNormalization() (L8)\n",
    "L10 = Dropout(0.1) (L9)\n",
    "\n",
    "# output layer and model summary\n",
    "output_layer = Dense (1, activation = 'linear') (L10)\n",
    "\n",
    "# Build a model\n",
    "from keras.models import Model\n",
    "dnn_model = Model(input_layer, output_layer)\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6931bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m271/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9450 - mean_absolute_error: 1.8795\n",
      "Epoch 1: val_loss improved from inf to 1.46271, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.7803 - mean_absolute_error: 1.8457 - val_loss: 1.4627 - val_mean_absolute_error: 0.8840\n",
      "Epoch 2/100\n",
      "\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6110 - mean_absolute_error: 0.9114\n",
      "Epoch 2: val_loss improved from 1.46271 to 1.07377, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6093 - mean_absolute_error: 0.9110 - val_loss: 1.0738 - val_mean_absolute_error: 0.7170\n",
      "Epoch 3/100\n",
      "\u001b[1m285/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2981 - mean_absolute_error: 0.8178\n",
      "Epoch 3: val_loss improved from 1.07377 to 1.02580, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.2982 - mean_absolute_error: 0.8178 - val_loss: 1.0258 - val_mean_absolute_error: 0.6959\n",
      "Epoch 4/100\n",
      "\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2694 - mean_absolute_error: 0.7970\n",
      "Epoch 4: val_loss did not improve from 1.02580\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2690 - mean_absolute_error: 0.7969 - val_loss: 1.0544 - val_mean_absolute_error: 0.7168\n",
      "Epoch 5/100\n",
      "\u001b[1m272/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1443 - mean_absolute_error: 0.7595\n",
      "Epoch 5: val_loss did not improve from 1.02580\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1438 - mean_absolute_error: 0.7593 - val_loss: 1.1245 - val_mean_absolute_error: 0.7769\n",
      "Epoch 6/100\n",
      "\u001b[1m285/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0802 - mean_absolute_error: 0.7320\n",
      "Epoch 6: val_loss improved from 1.02580 to 0.98683, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0805 - mean_absolute_error: 0.7321 - val_loss: 0.9868 - val_mean_absolute_error: 0.6860\n",
      "Epoch 7/100\n",
      "\u001b[1m273/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0983 - mean_absolute_error: 0.7285\n",
      "Epoch 7: val_loss improved from 0.98683 to 0.91320, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0973 - mean_absolute_error: 0.7288 - val_loss: 0.9132 - val_mean_absolute_error: 0.6387\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0624 - mean_absolute_error: 0.7193\n",
      "Epoch 8: val_loss improved from 0.91320 to 0.83466, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0622 - mean_absolute_error: 0.7193 - val_loss: 0.8347 - val_mean_absolute_error: 0.6015\n",
      "Epoch 9/100\n",
      "\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9576 - mean_absolute_error: 0.6874\n",
      "Epoch 9: val_loss did not improve from 0.83466\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9579 - mean_absolute_error: 0.6875 - val_loss: 0.8685 - val_mean_absolute_error: 0.6204\n",
      "Epoch 10/100\n",
      "\u001b[1m271/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9764 - mean_absolute_error: 0.6924\n",
      "Epoch 10: val_loss did not improve from 0.83466\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9760 - mean_absolute_error: 0.6925 - val_loss: 0.8611 - val_mean_absolute_error: 0.6510\n",
      "Epoch 11/100\n",
      "\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9465 - mean_absolute_error: 0.6990\n",
      "Epoch 11: val_loss improved from 0.83466 to 0.76059, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9466 - mean_absolute_error: 0.6990 - val_loss: 0.7606 - val_mean_absolute_error: 0.5835\n",
      "Epoch 12/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9699 - mean_absolute_error: 0.6882\n",
      "Epoch 12: val_loss did not improve from 0.76059\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9685 - mean_absolute_error: 0.6879 - val_loss: 0.7794 - val_mean_absolute_error: 0.5939\n",
      "Epoch 13/100\n",
      "\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9887 - mean_absolute_error: 0.6899\n",
      "Epoch 13: val_loss did not improve from 0.76059\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9851 - mean_absolute_error: 0.6892 - val_loss: 0.8217 - val_mean_absolute_error: 0.6141\n",
      "Epoch 14/100\n",
      "\u001b[1m269/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8560 - mean_absolute_error: 0.6665\n",
      "Epoch 14: val_loss improved from 0.76059 to 0.74128, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8571 - mean_absolute_error: 0.6662 - val_loss: 0.7413 - val_mean_absolute_error: 0.5730\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8857 - mean_absolute_error: 0.6756\n",
      "Epoch 15: val_loss did not improve from 0.74128\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8857 - mean_absolute_error: 0.6756 - val_loss: 0.8349 - val_mean_absolute_error: 0.6379\n",
      "Epoch 16/100\n",
      "\u001b[1m273/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8011 - mean_absolute_error: 0.6451\n",
      "Epoch 16: val_loss did not improve from 0.74128\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8034 - mean_absolute_error: 0.6452 - val_loss: 0.7586 - val_mean_absolute_error: 0.5924\n",
      "Epoch 17/100\n",
      "\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8307 - mean_absolute_error: 0.6317\n",
      "Epoch 17: val_loss improved from 0.74128 to 0.71891, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8304 - mean_absolute_error: 0.6317 - val_loss: 0.7189 - val_mean_absolute_error: 0.5746\n",
      "Epoch 18/100\n",
      "\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7952 - mean_absolute_error: 0.6416\n",
      "Epoch 18: val_loss improved from 0.71891 to 0.66037, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.7957 - mean_absolute_error: 0.6416 - val_loss: 0.6604 - val_mean_absolute_error: 0.5381\n",
      "Epoch 19/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8322 - mean_absolute_error: 0.6446\n",
      "Epoch 19: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8324 - mean_absolute_error: 0.6447 - val_loss: 0.7432 - val_mean_absolute_error: 0.5846\n",
      "Epoch 20/100\n",
      "\u001b[1m272/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8113 - mean_absolute_error: 0.6375\n",
      "Epoch 20: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8110 - mean_absolute_error: 0.6375 - val_loss: 0.6892 - val_mean_absolute_error: 0.5370\n",
      "Epoch 21/100\n",
      "\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7989 - mean_absolute_error: 0.6294\n",
      "Epoch 21: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7988 - mean_absolute_error: 0.6295 - val_loss: 0.7526 - val_mean_absolute_error: 0.6182\n",
      "Epoch 22/100\n",
      "\u001b[1m285/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7953 - mean_absolute_error: 0.6348\n",
      "Epoch 22: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7951 - mean_absolute_error: 0.6347 - val_loss: 0.7132 - val_mean_absolute_error: 0.5791\n",
      "Epoch 23/100\n",
      "\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7038 - mean_absolute_error: 0.5961\n",
      "Epoch 23: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7060 - mean_absolute_error: 0.5968 - val_loss: 0.7263 - val_mean_absolute_error: 0.5486\n",
      "Epoch 24/100\n",
      "\u001b[1m270/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7113 - mean_absolute_error: 0.6035\n",
      "Epoch 24: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7144 - mean_absolute_error: 0.6044 - val_loss: 0.8540 - val_mean_absolute_error: 0.6366\n",
      "Epoch 25/100\n",
      "\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7629 - mean_absolute_error: 0.6389\n",
      "Epoch 25: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7631 - mean_absolute_error: 0.6386 - val_loss: 0.7105 - val_mean_absolute_error: 0.5305\n",
      "Epoch 26/100\n",
      "\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7614 - mean_absolute_error: 0.6234\n",
      "Epoch 26: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7614 - mean_absolute_error: 0.6232 - val_loss: 0.6764 - val_mean_absolute_error: 0.5212\n",
      "Epoch 27/100\n",
      "\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6911 - mean_absolute_error: 0.5973\n",
      "Epoch 27: val_loss did not improve from 0.66037\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6922 - mean_absolute_error: 0.5975 - val_loss: 0.7840 - val_mean_absolute_error: 0.6035\n",
      "Epoch 28/100\n",
      "\u001b[1m272/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6999 - mean_absolute_error: 0.6042\n",
      "Epoch 28: val_loss improved from 0.66037 to 0.61796, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7015 - mean_absolute_error: 0.6043 - val_loss: 0.6180 - val_mean_absolute_error: 0.5199\n",
      "Epoch 29/100\n",
      "\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7092 - mean_absolute_error: 0.6032\n",
      "Epoch 29: val_loss did not improve from 0.61796\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7095 - mean_absolute_error: 0.6034 - val_loss: 0.6227 - val_mean_absolute_error: 0.5236\n",
      "Epoch 30/100\n",
      "\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7654 - mean_absolute_error: 0.6228\n",
      "Epoch 30: val_loss did not improve from 0.61796\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7650 - mean_absolute_error: 0.6227 - val_loss: 0.6456 - val_mean_absolute_error: 0.5165\n",
      "Epoch 31/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6956 - mean_absolute_error: 0.5947\n",
      "Epoch 31: val_loss did not improve from 0.61796\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6957 - mean_absolute_error: 0.5948 - val_loss: 0.6605 - val_mean_absolute_error: 0.5229\n",
      "Epoch 32/100\n",
      "\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6975 - mean_absolute_error: 0.6080\n",
      "Epoch 32: val_loss improved from 0.61796 to 0.60256, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6987 - mean_absolute_error: 0.6082 - val_loss: 0.6026 - val_mean_absolute_error: 0.5086\n",
      "Epoch 33/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6932 - mean_absolute_error: 0.5899\n",
      "Epoch 33: val_loss did not improve from 0.60256\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6931 - mean_absolute_error: 0.5898 - val_loss: 0.6074 - val_mean_absolute_error: 0.5291\n",
      "Epoch 34/100\n",
      "\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6542 - mean_absolute_error: 0.5840\n",
      "Epoch 34: val_loss improved from 0.60256 to 0.58489, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6544 - mean_absolute_error: 0.5840 - val_loss: 0.5849 - val_mean_absolute_error: 0.5142\n",
      "Epoch 35/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8017 - mean_absolute_error: 0.6267\n",
      "Epoch 35: val_loss did not improve from 0.58489\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7993 - mean_absolute_error: 0.6259 - val_loss: 0.6185 - val_mean_absolute_error: 0.5268\n",
      "Epoch 36/100\n",
      "\u001b[1m272/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6171 - mean_absolute_error: 0.5605\n",
      "Epoch 36: val_loss did not improve from 0.58489\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6196 - mean_absolute_error: 0.5617 - val_loss: 0.6415 - val_mean_absolute_error: 0.5317\n",
      "Epoch 37/100\n",
      "\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6723 - mean_absolute_error: 0.5863\n",
      "Epoch 37: val_loss did not improve from 0.58489\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6714 - mean_absolute_error: 0.5857 - val_loss: 0.6408 - val_mean_absolute_error: 0.5561\n",
      "Epoch 38/100\n",
      "\u001b[1m270/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6351 - mean_absolute_error: 0.5724\n",
      "Epoch 38: val_loss did not improve from 0.58489\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6377 - mean_absolute_error: 0.5733 - val_loss: 0.5952 - val_mean_absolute_error: 0.5151\n",
      "Epoch 39/100\n",
      "\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6262 - mean_absolute_error: 0.5645\n",
      "Epoch 39: val_loss improved from 0.58489 to 0.57698, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6268 - mean_absolute_error: 0.5646 - val_loss: 0.5770 - val_mean_absolute_error: 0.5083\n",
      "Epoch 40/100\n",
      "\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6282 - mean_absolute_error: 0.5673\n",
      "Epoch 40: val_loss did not improve from 0.57698\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6285 - mean_absolute_error: 0.5673 - val_loss: 0.6088 - val_mean_absolute_error: 0.5440\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6007 - mean_absolute_error: 0.5658\n",
      "Epoch 41: val_loss improved from 0.57698 to 0.56501, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6008 - mean_absolute_error: 0.5658 - val_loss: 0.5650 - val_mean_absolute_error: 0.4839\n",
      "Epoch 42/100\n",
      "\u001b[1m285/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6734 - mean_absolute_error: 0.5746\n",
      "Epoch 42: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6731 - mean_absolute_error: 0.5745 - val_loss: 0.5652 - val_mean_absolute_error: 0.4856\n",
      "Epoch 43/100\n",
      "\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6211 - mean_absolute_error: 0.5666\n",
      "Epoch 43: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6212 - mean_absolute_error: 0.5667 - val_loss: 0.6092 - val_mean_absolute_error: 0.5129\n",
      "Epoch 44/100\n",
      "\u001b[1m271/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5753 - mean_absolute_error: 0.5427\n",
      "Epoch 44: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5769 - mean_absolute_error: 0.5429 - val_loss: 0.6375 - val_mean_absolute_error: 0.5239\n",
      "Epoch 45/100\n",
      "\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5622 - mean_absolute_error: 0.5352\n",
      "Epoch 45: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5643 - mean_absolute_error: 0.5359 - val_loss: 0.6003 - val_mean_absolute_error: 0.5351\n",
      "Epoch 46/100\n",
      "\u001b[1m272/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6167 - mean_absolute_error: 0.5648\n",
      "Epoch 46: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6171 - mean_absolute_error: 0.5647 - val_loss: 0.7589 - val_mean_absolute_error: 0.5221\n",
      "Epoch 47/100\n",
      "\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5460 - mean_absolute_error: 0.5392\n",
      "Epoch 47: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5462 - mean_absolute_error: 0.5392 - val_loss: 0.6246 - val_mean_absolute_error: 0.5001\n",
      "Epoch 48/100\n",
      "\u001b[1m270/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5663 - mean_absolute_error: 0.5404\n",
      "Epoch 48: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5674 - mean_absolute_error: 0.5407 - val_loss: 1.2419 - val_mean_absolute_error: 0.5770\n",
      "Epoch 49/100\n",
      "\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7503 - mean_absolute_error: 0.5873\n",
      "Epoch 49: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7492 - mean_absolute_error: 0.5870 - val_loss: 0.5926 - val_mean_absolute_error: 0.5195\n",
      "Epoch 50/100\n",
      "\u001b[1m269/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6645 - mean_absolute_error: 0.5775\n",
      "Epoch 50: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6640 - mean_absolute_error: 0.5773 - val_loss: 0.6152 - val_mean_absolute_error: 0.4975\n",
      "Epoch 51/100\n",
      "\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6138 - mean_absolute_error: 0.5562\n",
      "Epoch 51: val_loss did not improve from 0.56501\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6134 - mean_absolute_error: 0.5561 - val_loss: 0.5968 - val_mean_absolute_error: 0.4864\n",
      "Epoch 52/100\n",
      "\u001b[1m273/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5814 - mean_absolute_error: 0.5471\n",
      "Epoch 52: val_loss improved from 0.56501 to 0.53046, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5812 - mean_absolute_error: 0.5472 - val_loss: 0.5305 - val_mean_absolute_error: 0.4965\n",
      "Epoch 53/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5631 - mean_absolute_error: 0.5476\n",
      "Epoch 53: val_loss did not improve from 0.53046\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5634 - mean_absolute_error: 0.5476 - val_loss: 0.5897 - val_mean_absolute_error: 0.4978\n",
      "Epoch 54/100\n",
      "\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5891 - mean_absolute_error: 0.5445\n",
      "Epoch 54: val_loss did not improve from 0.53046\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5889 - mean_absolute_error: 0.5445 - val_loss: 0.5528 - val_mean_absolute_error: 0.4578\n",
      "Epoch 55/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5678 - mean_absolute_error: 0.5408\n",
      "Epoch 55: val_loss did not improve from 0.53046\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5674 - mean_absolute_error: 0.5407 - val_loss: 0.6011 - val_mean_absolute_error: 0.5174\n",
      "Epoch 56/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5517 - mean_absolute_error: 0.5341\n",
      "Epoch 56: val_loss improved from 0.53046 to 0.49030, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5521 - mean_absolute_error: 0.5343 - val_loss: 0.4903 - val_mean_absolute_error: 0.4767\n",
      "Epoch 57/100\n",
      "\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5445 - mean_absolute_error: 0.5354\n",
      "Epoch 57: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5445 - mean_absolute_error: 0.5353 - val_loss: 0.5311 - val_mean_absolute_error: 0.4787\n",
      "Epoch 58/100\n",
      "\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5648 - mean_absolute_error: 0.5438\n",
      "Epoch 58: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5661 - mean_absolute_error: 0.5442 - val_loss: 0.6140 - val_mean_absolute_error: 0.5198\n",
      "Epoch 59/100\n",
      "\u001b[1m281/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5863 - mean_absolute_error: 0.5419\n",
      "Epoch 59: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5849 - mean_absolute_error: 0.5414 - val_loss: 0.5066 - val_mean_absolute_error: 0.4604\n",
      "Epoch 60/100\n",
      "\u001b[1m273/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5047 - mean_absolute_error: 0.5215\n",
      "Epoch 60: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5067 - mean_absolute_error: 0.5222 - val_loss: 0.8870 - val_mean_absolute_error: 0.5459\n",
      "Epoch 61/100\n",
      "\u001b[1m271/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5489 - mean_absolute_error: 0.5324\n",
      "Epoch 61: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5532 - mean_absolute_error: 0.5334 - val_loss: 0.6606 - val_mean_absolute_error: 0.5569\n",
      "Epoch 62/100\n",
      "\u001b[1m278/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5834 - mean_absolute_error: 0.5325\n",
      "Epoch 62: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5819 - mean_absolute_error: 0.5322 - val_loss: 0.5174 - val_mean_absolute_error: 0.4789\n",
      "Epoch 63/100\n",
      "\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5179 - mean_absolute_error: 0.5162\n",
      "Epoch 63: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5196 - mean_absolute_error: 0.5169 - val_loss: 0.5354 - val_mean_absolute_error: 0.4909\n",
      "Epoch 64/100\n",
      "\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5777 - mean_absolute_error: 0.5448\n",
      "Epoch 64: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5765 - mean_absolute_error: 0.5442 - val_loss: 0.5221 - val_mean_absolute_error: 0.4759\n",
      "Epoch 65/100\n",
      "\u001b[1m281/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5167 - mean_absolute_error: 0.5250\n",
      "Epoch 65: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5170 - mean_absolute_error: 0.5250 - val_loss: 0.5347 - val_mean_absolute_error: 0.4582\n",
      "Epoch 66/100\n",
      "\u001b[1m268/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4649 - mean_absolute_error: 0.5006\n",
      "Epoch 66: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4697 - mean_absolute_error: 0.5019 - val_loss: 0.5671 - val_mean_absolute_error: 0.4868\n",
      "Epoch 67/100\n",
      "\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4912 - mean_absolute_error: 0.5142\n",
      "Epoch 67: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4919 - mean_absolute_error: 0.5143 - val_loss: 0.5416 - val_mean_absolute_error: 0.4764\n",
      "Epoch 68/100\n",
      "\u001b[1m269/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4990 - mean_absolute_error: 0.5105\n",
      "Epoch 68: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4998 - mean_absolute_error: 0.5112 - val_loss: 0.5124 - val_mean_absolute_error: 0.4524\n",
      "Epoch 69/100\n",
      "\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5187 - mean_absolute_error: 0.5150\n",
      "Epoch 69: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5187 - mean_absolute_error: 0.5152 - val_loss: 0.5377 - val_mean_absolute_error: 0.4949\n",
      "Epoch 70/100\n",
      "\u001b[1m272/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5824 - mean_absolute_error: 0.5546\n",
      "Epoch 70: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5817 - mean_absolute_error: 0.5543 - val_loss: 0.5233 - val_mean_absolute_error: 0.4636\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4395 - mean_absolute_error: 0.4862\n",
      "Epoch 71: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4397 - mean_absolute_error: 0.4862 - val_loss: 0.7134 - val_mean_absolute_error: 0.5390\n",
      "Epoch 72/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4755 - mean_absolute_error: 0.5054\n",
      "Epoch 72: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4758 - mean_absolute_error: 0.5055 - val_loss: 0.5882 - val_mean_absolute_error: 0.4923\n",
      "Epoch 73/100\n",
      "\u001b[1m269/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4834 - mean_absolute_error: 0.5137\n",
      "Epoch 73: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4861 - mean_absolute_error: 0.5145 - val_loss: 0.5982 - val_mean_absolute_error: 0.4882\n",
      "Epoch 74/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5196 - mean_absolute_error: 0.5229\n",
      "Epoch 74: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5194 - mean_absolute_error: 0.5228 - val_loss: 0.5008 - val_mean_absolute_error: 0.4636\n",
      "Epoch 75/100\n",
      "\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4760 - mean_absolute_error: 0.4994\n",
      "Epoch 75: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4767 - mean_absolute_error: 0.4997 - val_loss: 0.5158 - val_mean_absolute_error: 0.4794\n",
      "Epoch 76/100\n",
      "\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4712 - mean_absolute_error: 0.5024\n",
      "Epoch 76: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4714 - mean_absolute_error: 0.5025 - val_loss: 0.5096 - val_mean_absolute_error: 0.4593\n",
      "Epoch 77/100\n",
      "\u001b[1m273/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4987 - mean_absolute_error: 0.5041\n",
      "Epoch 77: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5011 - mean_absolute_error: 0.5050 - val_loss: 0.5136 - val_mean_absolute_error: 0.4859\n",
      "Epoch 78/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4976 - mean_absolute_error: 0.5168\n",
      "Epoch 78: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4972 - mean_absolute_error: 0.5166 - val_loss: 0.5882 - val_mean_absolute_error: 0.4691\n",
      "Epoch 79/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4929 - mean_absolute_error: 0.5103\n",
      "Epoch 79: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4929 - mean_absolute_error: 0.5103 - val_loss: 0.5882 - val_mean_absolute_error: 0.4889\n",
      "Epoch 80/100\n",
      "\u001b[1m271/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4822 - mean_absolute_error: 0.5061\n",
      "Epoch 80: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4827 - mean_absolute_error: 0.5061 - val_loss: 0.5212 - val_mean_absolute_error: 0.4579\n",
      "Epoch 81/100\n",
      "\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4570 - mean_absolute_error: 0.4979\n",
      "Epoch 81: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4567 - mean_absolute_error: 0.4975 - val_loss: 0.5412 - val_mean_absolute_error: 0.4855\n",
      "Epoch 82/100\n",
      "\u001b[1m269/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4540 - mean_absolute_error: 0.5049\n",
      "Epoch 82: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4569 - mean_absolute_error: 0.5054 - val_loss: 0.7361 - val_mean_absolute_error: 0.4869\n",
      "Epoch 83/100\n",
      "\u001b[1m270/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5425 - mean_absolute_error: 0.5233\n",
      "Epoch 83: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5412 - mean_absolute_error: 0.5233 - val_loss: 0.5835 - val_mean_absolute_error: 0.4879\n",
      "Epoch 84/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4802 - mean_absolute_error: 0.5133\n",
      "Epoch 84: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4807 - mean_absolute_error: 0.5135 - val_loss: 0.6155 - val_mean_absolute_error: 0.4897\n",
      "Epoch 85/100\n",
      "\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4772 - mean_absolute_error: 0.5056\n",
      "Epoch 85: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4772 - mean_absolute_error: 0.5056 - val_loss: 0.5800 - val_mean_absolute_error: 0.4827\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4935 - mean_absolute_error: 0.5125\n",
      "Epoch 86: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4936 - mean_absolute_error: 0.5126 - val_loss: 0.5666 - val_mean_absolute_error: 0.4977\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5082 - mean_absolute_error: 0.5050\n",
      "Epoch 87: val_loss did not improve from 0.49030\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5082 - mean_absolute_error: 0.5050 - val_loss: 0.5811 - val_mean_absolute_error: 0.5063\n",
      "Epoch 88/100\n",
      "\u001b[1m278/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4944 - mean_absolute_error: 0.5219\n",
      "Epoch 88: val_loss improved from 0.49030 to 0.46564, saving model to Results/Best_model/dnn_model.keras\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4942 - mean_absolute_error: 0.5214 - val_loss: 0.4656 - val_mean_absolute_error: 0.4436\n",
      "Epoch 89/100\n",
      "\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4313 - mean_absolute_error: 0.4890\n",
      "Epoch 89: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4315 - mean_absolute_error: 0.4891 - val_loss: 0.5136 - val_mean_absolute_error: 0.4768\n",
      "Epoch 90/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4928 - mean_absolute_error: 0.5139\n",
      "Epoch 90: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4919 - mean_absolute_error: 0.5136 - val_loss: 0.5511 - val_mean_absolute_error: 0.4663\n",
      "Epoch 91/100\n",
      "\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4417 - mean_absolute_error: 0.4915\n",
      "Epoch 91: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4423 - mean_absolute_error: 0.4917 - val_loss: 0.5175 - val_mean_absolute_error: 0.4528\n",
      "Epoch 92/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4317 - mean_absolute_error: 0.4874\n",
      "Epoch 92: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4325 - mean_absolute_error: 0.4876 - val_loss: 0.6220 - val_mean_absolute_error: 0.4972\n",
      "Epoch 93/100\n",
      "\u001b[1m270/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5053 - mean_absolute_error: 0.4953\n",
      "Epoch 93: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5032 - mean_absolute_error: 0.4953 - val_loss: 0.4991 - val_mean_absolute_error: 0.4495\n",
      "Epoch 94/100\n",
      "\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4931 - mean_absolute_error: 0.4953\n",
      "Epoch 94: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4925 - mean_absolute_error: 0.4952 - val_loss: 0.5848 - val_mean_absolute_error: 0.4882\n",
      "Epoch 95/100\n",
      "\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4749 - mean_absolute_error: 0.4944\n",
      "Epoch 95: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4744 - mean_absolute_error: 0.4942 - val_loss: 0.8451 - val_mean_absolute_error: 0.4785\n",
      "Epoch 96/100\n",
      "\u001b[1m271/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4904 - mean_absolute_error: 0.5163\n",
      "Epoch 96: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4908 - mean_absolute_error: 0.5160 - val_loss: 0.4770 - val_mean_absolute_error: 0.4494\n",
      "Epoch 97/100\n",
      "\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4686 - mean_absolute_error: 0.5101\n",
      "Epoch 97: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4694 - mean_absolute_error: 0.5103 - val_loss: 0.5291 - val_mean_absolute_error: 0.4468\n",
      "Epoch 98/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4552 - mean_absolute_error: 0.4992\n",
      "Epoch 98: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4560 - mean_absolute_error: 0.4995 - val_loss: 0.6493 - val_mean_absolute_error: 0.4777\n",
      "Epoch 99/100\n",
      "\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4635 - mean_absolute_error: 0.4870\n",
      "Epoch 99: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4644 - mean_absolute_error: 0.4874 - val_loss: 0.5027 - val_mean_absolute_error: 0.4599\n",
      "Epoch 100/100\n",
      "\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4889 - mean_absolute_error: 0.5072\n",
      "Epoch 100: val_loss did not improve from 0.46564\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4873 - mean_absolute_error: 0.5066 - val_loss: 0.5427 - val_mean_absolute_error: 0.4462\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# Save best model using checkpoint strategy\n",
    "filepath = 'Results/Best_model/dnn_model.keras'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto') #auto: The direction is automatically inferred from the name of the monitored quantity. For metrics like val_loss, where a decrease is better, it sets the mode to min. Conversely, for metrics like accuracy, where an increase is better, it sets the mode to max.\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# compilation of model\n",
    "dnn_model.compile(optimizer=Adam(learning_rate = 0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# modelfitting\n",
    "\n",
    "history = dnn_model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5d6fe90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "R2 score is: 0.93\n",
      "RMSE is: 0.57\n",
      "RRMSE is: 20.32%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the saved model\n",
    "Saved_model_dnn = load_model('Results/Best_model/dnn_model.keras')\n",
    "\n",
    "# Make predictions on training data\n",
    "y_pred = Saved_model_dnn.predict(X_train_scaled)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rrmse = rmse/np.mean(y_test)*100\n",
    "print(f'R2 score is: {r2:.2f}')\n",
    "print(f'RMSE is: {rmse:.2f}')\n",
    "print(f'RRMSE is: {rrmse:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "749232d4-4844-43b2-89f2-de80036d9355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step\n",
      "R2 score is: 0.85\n",
      "RMSE is: 0.80\n",
      "RRMSE is: 28.59%\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics for testing data\n",
    "y_pred = Saved_model_dnn.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rrmse = rmse/np.mean(y_test)*100\n",
    "print(f'R2 score is: {r2:.2f}')\n",
    "print(f'RMSE is: {rmse:.2f}')\n",
    "print(f'RRMSE is: {rrmse:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e9f62a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='29bcddf3-3011-49ce-86e5-efd96b4f258a'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc9eeb5ec50>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# visualize the training loss across different epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d5dd312c-dbe1-4ff7-9ae1-936e89ce10b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='fd9aaaa3-91de-4cc9-aa6d-8665ae36460d'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sccaltter plot for testing data sets\n",
    "plt.scatter(y_test, y_pred, color='green')\n",
    "plt.xlabel('Observed ETa, mm/day')\n",
    "plt.ylabel('Predicted ETa, mm/day')\n",
    "plt.title('Observed vs Predicted ETa Using LR')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw = 3)  # Adds a reference line\n",
    "\n",
    "# Annotating the plot with the performance metrics\n",
    "textstr = '\\n'.join((\n",
    "    'Testing set',\n",
    "    f'R²: {r2_cnn:.2f}',\n",
    "    f'MSE: {mse_cnn:.2f}',\n",
    "    f'RMSE: {rmse_cnn:.2f} mm/day'\n",
    "))\n",
    "# These are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# Place a text box in upper left in axes coords\n",
    "plt.gca().text(0.04, 0.96, textstr, transform=plt.gca().transAxes, fontsize=12,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f85b0",
   "metadata": {},
   "source": [
    "# 4.2. 1D Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97dbfc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 13:18:53.457060: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 13:18:53.713891: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 13:18:53.966443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-08 13:18:54.164459: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-08 13:18:54.227545: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-08 13:18:54.647277: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 13:18:57.898372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47584db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to fit the model input\n",
    "X_train_scaled_reshape = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_scaled_reshape = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3789613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/geoai/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,601</span> (193.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,601\u001b[0m (193.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,601</span> (193.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,601\u001b[0m (193.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Suppose you have a 1D input sequence: [1, 2, 3, 4, 5].\n",
    "# You define a filter (or kernel) with values [0.2, 0.5].\n",
    "# The convolution operation would start by placing the filter at the beginning of the sequence and computing the dot product: (1*0.2) + (2*0.5) = 0.2 + 1.0 = 1.2\n",
    "# A convolutional layer typically has multiple filters. Each filter detects different features or patterns in the input data.\n",
    "# filters=64: This means the convolutional layer has 64 different filters (kernels). Each of these filters will produce a separate feature map, so the output of this convolutional layer will have 64 channels.\n",
    "# kernel_size=2: Each filter will cover 2 consecutive elements of the input data at a time.  \n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# It reduces the dimensionality of the input, which helps to decrease the computational load and to capture dominant features more effectively.\n",
    "# Input: [1, 3, 2, 5, 4, 6]\n",
    "# With pool_size=2, the max pooling operation will:\n",
    "# Look at the first two elements [1, 3] and take the maximum, which is 3.\n",
    "# Move the window to the next two elements [2, 5] and take the maximum, which is 5.\n",
    "# Move the window to the next two elements [4, 6] and take the maximum, which is 6.\n",
    "# Output: [3, 5, 6]\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))# Added more neurons for a potentially deeper representation\n",
    "model.add(Dropout(0.15))  # Dropout layer to reduce overfitting\n",
    "model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2027f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m530/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7293\n",
      "Epoch 1: val_loss improved from inf to 1.18157, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.6492 - val_loss: 1.1816\n",
      "Epoch 2/200\n",
      "\u001b[1m533/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1979\n",
      "Epoch 2: val_loss improved from 1.18157 to 1.06877, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.2005 - val_loss: 1.0688\n",
      "Epoch 3/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1537\n",
      "Epoch 3: val_loss improved from 1.06877 to 1.04976, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1541 - val_loss: 1.0498\n",
      "Epoch 4/200\n",
      "\u001b[1m555/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1177\n",
      "Epoch 4: val_loss improved from 1.04976 to 0.98762, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1175 - val_loss: 0.9876\n",
      "Epoch 5/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1281\n",
      "Epoch 5: val_loss improved from 0.98762 to 0.95060, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1264 - val_loss: 0.9506\n",
      "Epoch 6/200\n",
      "\u001b[1m574/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0848\n",
      "Epoch 6: val_loss improved from 0.95060 to 0.93620, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0848 - val_loss: 0.9362\n",
      "Epoch 7/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9721\n",
      "Epoch 7: val_loss improved from 0.93620 to 0.90786, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9750 - val_loss: 0.9079\n",
      "Epoch 8/200\n",
      "\u001b[1m555/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0413\n",
      "Epoch 8: val_loss improved from 0.90786 to 0.90500, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0409 - val_loss: 0.9050\n",
      "Epoch 9/200\n",
      "\u001b[1m531/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9506\n",
      "Epoch 9: val_loss improved from 0.90500 to 0.85725, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9564 - val_loss: 0.8572\n",
      "Epoch 10/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9335\n",
      "Epoch 10: val_loss did not improve from 0.85725\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9359 - val_loss: 0.8651\n",
      "Epoch 11/200\n",
      "\u001b[1m540/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9722\n",
      "Epoch 11: val_loss improved from 0.85725 to 0.82413, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9727 - val_loss: 0.8241\n",
      "Epoch 12/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9617\n",
      "Epoch 12: val_loss did not improve from 0.82413\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9607 - val_loss: 0.8460\n",
      "Epoch 13/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8773\n",
      "Epoch 13: val_loss improved from 0.82413 to 0.81330, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8795 - val_loss: 0.8133\n",
      "Epoch 14/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8939\n",
      "Epoch 14: val_loss improved from 0.81330 to 0.80684, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8955 - val_loss: 0.8068\n",
      "Epoch 15/200\n",
      "\u001b[1m556/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9488\n",
      "Epoch 15: val_loss did not improve from 0.80684\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9480 - val_loss: 0.8189\n",
      "Epoch 16/200\n",
      "\u001b[1m555/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8885\n",
      "Epoch 16: val_loss improved from 0.80684 to 0.79372, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8891 - val_loss: 0.7937\n",
      "Epoch 17/200\n",
      "\u001b[1m556/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.9233\n",
      "Epoch 17: val_loss did not improve from 0.79372\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9227 - val_loss: 0.8778\n",
      "Epoch 18/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8647\n",
      "Epoch 18: val_loss improved from 0.79372 to 0.78672, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8661 - val_loss: 0.7867\n",
      "Epoch 19/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9277\n",
      "Epoch 19: val_loss improved from 0.78672 to 0.76024, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9245 - val_loss: 0.7602\n",
      "Epoch 20/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9391\n",
      "Epoch 20: val_loss did not improve from 0.76024\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9344 - val_loss: 0.9448\n",
      "Epoch 21/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8286\n",
      "Epoch 21: val_loss did not improve from 0.76024\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8300 - val_loss: 0.7790\n",
      "Epoch 22/200\n",
      "\u001b[1m544/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8201\n",
      "Epoch 22: val_loss did not improve from 0.76024\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8222 - val_loss: 0.7727\n",
      "Epoch 23/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8396\n",
      "Epoch 23: val_loss did not improve from 0.76024\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8395 - val_loss: 0.8162\n",
      "Epoch 24/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8476\n",
      "Epoch 24: val_loss did not improve from 0.76024\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8474 - val_loss: 0.7707\n",
      "Epoch 25/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8319\n",
      "Epoch 25: val_loss improved from 0.76024 to 0.73971, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8317 - val_loss: 0.7397\n",
      "Epoch 26/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8273\n",
      "Epoch 26: val_loss improved from 0.73971 to 0.73334, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8278 - val_loss: 0.7333\n",
      "Epoch 27/200\n",
      "\u001b[1m556/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.7936\n",
      "Epoch 27: val_loss improved from 0.73334 to 0.71098, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7941 - val_loss: 0.7110\n",
      "Epoch 28/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8025\n",
      "Epoch 28: val_loss improved from 0.71098 to 0.69971, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8027 - val_loss: 0.6997\n",
      "Epoch 29/200\n",
      "\u001b[1m544/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7335\n",
      "Epoch 29: val_loss improved from 0.69971 to 0.69233, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7376 - val_loss: 0.6923\n",
      "Epoch 30/200\n",
      "\u001b[1m564/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7672\n",
      "Epoch 30: val_loss did not improve from 0.69233\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7679 - val_loss: 0.7146\n",
      "Epoch 31/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7570\n",
      "Epoch 31: val_loss did not improve from 0.69233\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7583 - val_loss: 0.7189\n",
      "Epoch 32/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7498\n",
      "Epoch 32: val_loss did not improve from 0.69233\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7511 - val_loss: 0.7396\n",
      "Epoch 33/200\n",
      "\u001b[1m538/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7297\n",
      "Epoch 33: val_loss did not improve from 0.69233\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7328 - val_loss: 0.7720\n",
      "Epoch 34/200\n",
      "\u001b[1m552/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7627\n",
      "Epoch 34: val_loss improved from 0.69233 to 0.69117, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7631 - val_loss: 0.6912\n",
      "Epoch 35/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7736\n",
      "Epoch 35: val_loss did not improve from 0.69117\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7729 - val_loss: 0.7083\n",
      "Epoch 36/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6922\n",
      "Epoch 36: val_loss improved from 0.69117 to 0.66805, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6952 - val_loss: 0.6681\n",
      "Epoch 37/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7468\n",
      "Epoch 37: val_loss improved from 0.66805 to 0.66697, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7474 - val_loss: 0.6670\n",
      "Epoch 38/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7546\n",
      "Epoch 38: val_loss did not improve from 0.66697\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7540 - val_loss: 0.8365\n",
      "Epoch 39/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7544\n",
      "Epoch 39: val_loss did not improve from 0.66697\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7546 - val_loss: 0.7148\n",
      "Epoch 40/200\n",
      "\u001b[1m534/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8066\n",
      "Epoch 40: val_loss did not improve from 0.66697\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8028 - val_loss: 0.7076\n",
      "Epoch 41/200\n",
      "\u001b[1m559/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.7446\n",
      "Epoch 41: val_loss did not improve from 0.66697\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7446 - val_loss: 0.7041\n",
      "Epoch 42/200\n",
      "\u001b[1m552/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7252\n",
      "Epoch 42: val_loss did not improve from 0.66697\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7261 - val_loss: 0.6915\n",
      "Epoch 43/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7127\n",
      "Epoch 43: val_loss did not improve from 0.66697\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7134 - val_loss: 0.6813\n",
      "Epoch 44/200\n",
      "\u001b[1m564/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.7009\n",
      "Epoch 44: val_loss improved from 0.66697 to 0.65063, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7016 - val_loss: 0.6506\n",
      "Epoch 45/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7627\n",
      "Epoch 45: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7616 - val_loss: 0.6925\n",
      "Epoch 46/200\n",
      "\u001b[1m546/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7029 \n",
      "Epoch 46: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7038 - val_loss: 0.7886\n",
      "Epoch 47/200\n",
      "\u001b[1m552/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6719\n",
      "Epoch 47: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6742 - val_loss: 0.6815\n",
      "Epoch 48/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7303\n",
      "Epoch 48: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7292 - val_loss: 0.6856\n",
      "Epoch 49/200\n",
      "\u001b[1m527/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7456\n",
      "Epoch 49: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7446 - val_loss: 0.7342\n",
      "Epoch 50/200\n",
      "\u001b[1m551/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6731\n",
      "Epoch 50: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6740 - val_loss: 0.7000\n",
      "Epoch 51/200\n",
      "\u001b[1m562/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.7177\n",
      "Epoch 51: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7175 - val_loss: 0.6823\n",
      "Epoch 52/200\n",
      "\u001b[1m537/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7180\n",
      "Epoch 52: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7176 - val_loss: 0.6655\n",
      "Epoch 53/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6738\n",
      "Epoch 53: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6751 - val_loss: 0.6712\n",
      "Epoch 54/200\n",
      "\u001b[1m536/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7162\n",
      "Epoch 54: val_loss did not improve from 0.65063\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7141 - val_loss: 0.6549\n",
      "Epoch 55/200\n",
      "\u001b[1m561/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.6730\n",
      "Epoch 55: val_loss improved from 0.65063 to 0.62572, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6738 - val_loss: 0.6257\n",
      "Epoch 56/200\n",
      "\u001b[1m558/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.6862\n",
      "Epoch 56: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6866 - val_loss: 0.6656\n",
      "Epoch 57/200\n",
      "\u001b[1m529/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6576\n",
      "Epoch 57: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6617 - val_loss: 0.6641\n",
      "Epoch 58/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6814\n",
      "Epoch 58: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6812 - val_loss: 0.6950\n",
      "Epoch 59/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7319\n",
      "Epoch 59: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7303 - val_loss: 0.7296\n",
      "Epoch 60/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6681\n",
      "Epoch 60: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6684 - val_loss: 0.6496\n",
      "Epoch 61/200\n",
      "\u001b[1m546/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6423\n",
      "Epoch 61: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6437 - val_loss: 0.6704\n",
      "Epoch 62/200\n",
      "\u001b[1m566/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.6689\n",
      "Epoch 62: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6690 - val_loss: 0.6524\n",
      "Epoch 63/200\n",
      "\u001b[1m556/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6762  \n",
      "Epoch 63: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6762 - val_loss: 0.6529\n",
      "Epoch 64/200\n",
      "\u001b[1m546/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6640\n",
      "Epoch 64: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7143\n",
      "Epoch 65/200\n",
      "\u001b[1m561/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.6358\n",
      "Epoch 65: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6367 - val_loss: 0.6264\n",
      "Epoch 66/200\n",
      "\u001b[1m531/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6473\n",
      "Epoch 66: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6479 - val_loss: 0.6425\n",
      "Epoch 67/200\n",
      "\u001b[1m572/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.6284\n",
      "Epoch 67: val_loss did not improve from 0.62572\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6286 - val_loss: 0.6431\n",
      "Epoch 68/200\n",
      "\u001b[1m557/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6429\n",
      "Epoch 68: val_loss improved from 0.62572 to 0.61876, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6433 - val_loss: 0.6188\n",
      "Epoch 69/200\n",
      "\u001b[1m539/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6906\n",
      "Epoch 69: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6879 - val_loss: 0.6594\n",
      "Epoch 70/200\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.6509\n",
      "Epoch 70: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6510 - val_loss: 0.6794\n",
      "Epoch 71/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6379\n",
      "Epoch 71: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6386 - val_loss: 0.6449\n",
      "Epoch 72/200\n",
      "\u001b[1m542/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6651\n",
      "Epoch 72: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.6560\n",
      "Epoch 73/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6429\n",
      "Epoch 73: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6427 - val_loss: 0.6428\n",
      "Epoch 74/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6199\n",
      "Epoch 74: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6208 - val_loss: 0.6226\n",
      "Epoch 75/200\n",
      "\u001b[1m569/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.6577\n",
      "Epoch 75: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6577 - val_loss: 0.6310\n",
      "Epoch 76/200\n",
      "\u001b[1m555/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6294 \n",
      "Epoch 76: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6297 - val_loss: 0.6305\n",
      "Epoch 77/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6545\n",
      "Epoch 77: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6539 - val_loss: 0.6394\n",
      "Epoch 78/200\n",
      "\u001b[1m569/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.5926\n",
      "Epoch 78: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5930 - val_loss: 0.6551\n",
      "Epoch 79/200\n",
      "\u001b[1m570/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.6273\n",
      "Epoch 79: val_loss did not improve from 0.61876\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6273 - val_loss: 0.6200\n",
      "Epoch 80/200\n",
      "\u001b[1m527/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6476\n",
      "Epoch 80: val_loss improved from 0.61876 to 0.60309, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6485 - val_loss: 0.6031\n",
      "Epoch 81/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6021\n",
      "Epoch 81: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6028 - val_loss: 0.6356\n",
      "Epoch 82/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6310\n",
      "Epoch 82: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6311 - val_loss: 0.6469\n",
      "Epoch 83/200\n",
      "\u001b[1m557/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.5860\n",
      "Epoch 83: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5874 - val_loss: 0.6349\n",
      "Epoch 84/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6066\n",
      "Epoch 84: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6073 - val_loss: 0.6489\n",
      "Epoch 85/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5830 \n",
      "Epoch 85: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5840 - val_loss: 0.6144\n",
      "Epoch 86/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6152\n",
      "Epoch 86: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6164 - val_loss: 0.6726\n",
      "Epoch 87/200\n",
      "\u001b[1m556/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.6600\n",
      "Epoch 87: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6584 - val_loss: 0.7122\n",
      "Epoch 88/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5965\n",
      "Epoch 88: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5972 - val_loss: 0.6277\n",
      "Epoch 89/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5917\n",
      "Epoch 89: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5927 - val_loss: 0.6330\n",
      "Epoch 90/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6154\n",
      "Epoch 90: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6151 - val_loss: 0.6446\n",
      "Epoch 91/200\n",
      "\u001b[1m536/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.5865\n",
      "Epoch 91: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5869 - val_loss: 0.6244\n",
      "Epoch 92/200\n",
      "\u001b[1m558/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6152  \n",
      "Epoch 92: val_loss did not improve from 0.60309\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6144 - val_loss: 0.6530\n",
      "Epoch 93/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6435\n",
      "Epoch 93: val_loss improved from 0.60309 to 0.59795, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6411 - val_loss: 0.5979\n",
      "Epoch 94/200\n",
      "\u001b[1m560/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.5825\n",
      "Epoch 94: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5829 - val_loss: 0.6348\n",
      "Epoch 95/200\n",
      "\u001b[1m566/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.5851\n",
      "Epoch 95: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5851 - val_loss: 0.6593\n",
      "Epoch 96/200\n",
      "\u001b[1m567/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.5760\n",
      "Epoch 96: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5765 - val_loss: 0.6598\n",
      "Epoch 97/200\n",
      "\u001b[1m565/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.6111\n",
      "Epoch 97: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6109 - val_loss: 0.6257\n",
      "Epoch 98/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5864 \n",
      "Epoch 98: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5863 - val_loss: 0.6006\n",
      "Epoch 99/200\n",
      "\u001b[1m565/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.6021\n",
      "Epoch 99: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6018 - val_loss: 0.6150\n",
      "Epoch 100/200\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.5861\n",
      "Epoch 100: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5861 - val_loss: 0.6191\n",
      "Epoch 101/200\n",
      "\u001b[1m556/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5900\n",
      "Epoch 101: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5905 - val_loss: 0.6062\n",
      "Epoch 102/200\n",
      "\u001b[1m560/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.5888\n",
      "Epoch 102: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5888 - val_loss: 0.6184\n",
      "Epoch 103/200\n",
      "\u001b[1m539/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5494\n",
      "Epoch 103: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5502 - val_loss: 0.6023\n",
      "Epoch 104/200\n",
      "\u001b[1m557/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.5736\n",
      "Epoch 104: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5736 - val_loss: 0.6259\n",
      "Epoch 105/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5695\n",
      "Epoch 105: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5706 - val_loss: 0.6316\n",
      "Epoch 106/200\n",
      "\u001b[1m533/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5676\n",
      "Epoch 106: val_loss did not improve from 0.59795\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5677 - val_loss: 0.6636\n",
      "Epoch 107/200\n",
      "\u001b[1m551/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5840\n",
      "Epoch 107: val_loss improved from 0.59795 to 0.59316, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5843 - val_loss: 0.5932\n",
      "Epoch 108/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5475\n",
      "Epoch 108: val_loss improved from 0.59316 to 0.59254, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5491 - val_loss: 0.5925\n",
      "Epoch 109/200\n",
      "\u001b[1m546/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5482\n",
      "Epoch 109: val_loss did not improve from 0.59254\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5494 - val_loss: 0.6064\n",
      "Epoch 110/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5511\n",
      "Epoch 110: val_loss did not improve from 0.59254\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5519 - val_loss: 0.6010\n",
      "Epoch 111/200\n",
      "\u001b[1m537/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5505\n",
      "Epoch 111: val_loss did not improve from 0.59254\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5514 - val_loss: 0.6270\n",
      "Epoch 112/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5787 \n",
      "Epoch 112: val_loss did not improve from 0.59254\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5778 - val_loss: 0.6472\n",
      "Epoch 113/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6309\n",
      "Epoch 113: val_loss improved from 0.59254 to 0.57412, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6272 - val_loss: 0.5741\n",
      "Epoch 114/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5498\n",
      "Epoch 114: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5506 - val_loss: 0.5931\n",
      "Epoch 115/200\n",
      "\u001b[1m552/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5432\n",
      "Epoch 115: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5437 - val_loss: 0.6082\n",
      "Epoch 116/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5639\n",
      "Epoch 116: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5633 - val_loss: 0.6147\n",
      "Epoch 117/200\n",
      "\u001b[1m530/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5653\n",
      "Epoch 117: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5644 - val_loss: 0.5963\n",
      "Epoch 118/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5581\n",
      "Epoch 118: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5586 - val_loss: 0.6028\n",
      "Epoch 119/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5146\n",
      "Epoch 119: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5168 - val_loss: 0.6257\n",
      "Epoch 120/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5257\n",
      "Epoch 120: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5268 - val_loss: 0.6169\n",
      "Epoch 121/200\n",
      "\u001b[1m542/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5167\n",
      "Epoch 121: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5188 - val_loss: 0.5852\n",
      "Epoch 122/200\n",
      "\u001b[1m546/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5488\n",
      "Epoch 122: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5489 - val_loss: 0.6779\n",
      "Epoch 123/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5644\n",
      "Epoch 123: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5635 - val_loss: 0.6305\n",
      "Epoch 124/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5529\n",
      "Epoch 124: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5540 - val_loss: 0.6214\n",
      "Epoch 125/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5016\n",
      "Epoch 125: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5046 - val_loss: 0.6956\n",
      "Epoch 126/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5703\n",
      "Epoch 126: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5687 - val_loss: 0.5906\n",
      "Epoch 127/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5209\n",
      "Epoch 127: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5213 - val_loss: 0.6848\n",
      "Epoch 128/200\n",
      "\u001b[1m551/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5374\n",
      "Epoch 128: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5370 - val_loss: 0.5994\n",
      "Epoch 129/200\n",
      "\u001b[1m535/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5148\n",
      "Epoch 129: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5165 - val_loss: 0.6001\n",
      "Epoch 130/200\n",
      "\u001b[1m559/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.5472\n",
      "Epoch 130: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5474 - val_loss: 0.5978\n",
      "Epoch 131/200\n",
      "\u001b[1m567/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.5557\n",
      "Epoch 131: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5554 - val_loss: 0.6017\n",
      "Epoch 132/200\n",
      "\u001b[1m559/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.5646\n",
      "Epoch 132: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5643 - val_loss: 0.6081\n",
      "Epoch 133/200\n",
      "\u001b[1m542/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5850\n",
      "Epoch 133: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5831 - val_loss: 0.5934\n",
      "Epoch 134/200\n",
      "\u001b[1m558/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5279\n",
      "Epoch 134: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5281 - val_loss: 0.6521\n",
      "Epoch 135/200\n",
      "\u001b[1m540/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5348\n",
      "Epoch 135: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5352 - val_loss: 0.6082\n",
      "Epoch 136/200\n",
      "\u001b[1m538/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5296\n",
      "Epoch 136: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5296 - val_loss: 0.6166\n",
      "Epoch 137/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5179\n",
      "Epoch 137: val_loss did not improve from 0.57412\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5188 - val_loss: 0.5765\n",
      "Epoch 138/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5184\n",
      "Epoch 138: val_loss improved from 0.57412 to 0.55460, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5188 - val_loss: 0.5546\n",
      "Epoch 139/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4935\n",
      "Epoch 139: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4944 - val_loss: 0.6003\n",
      "Epoch 140/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5112\n",
      "Epoch 140: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5118 - val_loss: 0.6213\n",
      "Epoch 141/200\n",
      "\u001b[1m557/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5450\n",
      "Epoch 141: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5446 - val_loss: 0.6488\n",
      "Epoch 142/200\n",
      "\u001b[1m552/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5377\n",
      "Epoch 142: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5367 - val_loss: 0.5935\n",
      "Epoch 143/200\n",
      "\u001b[1m537/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5257\n",
      "Epoch 143: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5251 - val_loss: 0.6293\n",
      "Epoch 144/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5062\n",
      "Epoch 144: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5074 - val_loss: 0.6464\n",
      "Epoch 145/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4930\n",
      "Epoch 145: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4939 - val_loss: 0.6239\n",
      "Epoch 146/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5168\n",
      "Epoch 146: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5173 - val_loss: 0.5730\n",
      "Epoch 147/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5124\n",
      "Epoch 147: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5116 - val_loss: 0.5743\n",
      "Epoch 148/200\n",
      "\u001b[1m542/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5347\n",
      "Epoch 148: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5342 - val_loss: 0.5873\n",
      "Epoch 149/200\n",
      "\u001b[1m547/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4885\n",
      "Epoch 149: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4893 - val_loss: 0.6903\n",
      "Epoch 150/200\n",
      "\u001b[1m542/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5189\n",
      "Epoch 150: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5181 - val_loss: 0.5799\n",
      "Epoch 151/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5255\n",
      "Epoch 151: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5248 - val_loss: 0.6117\n",
      "Epoch 152/200\n",
      "\u001b[1m559/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.5503\n",
      "Epoch 152: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5491 - val_loss: 0.6185\n",
      "Epoch 153/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5020\n",
      "Epoch 153: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5020 - val_loss: 0.5779\n",
      "Epoch 154/200\n",
      "\u001b[1m542/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4899\n",
      "Epoch 154: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4896 - val_loss: 0.5674\n",
      "Epoch 155/200\n",
      "\u001b[1m557/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4957\n",
      "Epoch 155: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4960 - val_loss: 0.5641\n",
      "Epoch 156/200\n",
      "\u001b[1m551/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4986\n",
      "Epoch 156: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4993 - val_loss: 0.5790\n",
      "Epoch 157/200\n",
      "\u001b[1m562/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.4893\n",
      "Epoch 157: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4900 - val_loss: 0.6095\n",
      "Epoch 158/200\n",
      "\u001b[1m544/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4818\n",
      "Epoch 158: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4828 - val_loss: 0.5870\n",
      "Epoch 159/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5112\n",
      "Epoch 159: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5110 - val_loss: 0.5755\n",
      "Epoch 160/200\n",
      "\u001b[1m561/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.5042\n",
      "Epoch 160: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5044 - val_loss: 0.5922\n",
      "Epoch 161/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4798\n",
      "Epoch 161: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4802 - val_loss: 0.6723\n",
      "Epoch 162/200\n",
      "\u001b[1m540/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5072\n",
      "Epoch 162: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5066 - val_loss: 0.5747\n",
      "Epoch 163/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4959\n",
      "Epoch 163: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4960 - val_loss: 0.5600\n",
      "Epoch 164/200\n",
      "\u001b[1m552/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4628\n",
      "Epoch 164: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4641 - val_loss: 0.5845\n",
      "Epoch 165/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5113\n",
      "Epoch 165: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5109 - val_loss: 0.6390\n",
      "Epoch 166/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4669 \n",
      "Epoch 166: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4672 - val_loss: 0.5575\n",
      "Epoch 167/200\n",
      "\u001b[1m574/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.4981\n",
      "Epoch 167: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4981 - val_loss: 0.6170\n",
      "Epoch 168/200\n",
      "\u001b[1m528/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4808\n",
      "Epoch 168: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4814 - val_loss: 0.6169\n",
      "Epoch 169/200\n",
      "\u001b[1m565/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.4898\n",
      "Epoch 169: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4900 - val_loss: 0.6208\n",
      "Epoch 170/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4836\n",
      "Epoch 170: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4838 - val_loss: 0.5997\n",
      "Epoch 171/200\n",
      "\u001b[1m572/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.4611\n",
      "Epoch 171: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4612 - val_loss: 0.5866\n",
      "Epoch 172/200\n",
      "\u001b[1m544/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4635\n",
      "Epoch 172: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4649 - val_loss: 0.6118\n",
      "Epoch 173/200\n",
      "\u001b[1m566/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.5025\n",
      "Epoch 173: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5023 - val_loss: 0.6046\n",
      "Epoch 174/200\n",
      "\u001b[1m545/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4996\n",
      "Epoch 174: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4984 - val_loss: 0.6020\n",
      "Epoch 175/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4738\n",
      "Epoch 175: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4746 - val_loss: 0.6168\n",
      "Epoch 176/200\n",
      "\u001b[1m558/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.5102\n",
      "Epoch 176: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5096 - val_loss: 0.5870\n",
      "Epoch 177/200\n",
      "\u001b[1m550/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5308\n",
      "Epoch 177: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5295 - val_loss: 0.6220\n",
      "Epoch 178/200\n",
      "\u001b[1m551/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4914 \n",
      "Epoch 178: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4913 - val_loss: 0.5557\n",
      "Epoch 179/200\n",
      "\u001b[1m566/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.4480\n",
      "Epoch 179: val_loss did not improve from 0.55460\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4482 - val_loss: 0.6036\n",
      "Epoch 180/200\n",
      "\u001b[1m543/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4552\n",
      "Epoch 180: val_loss improved from 0.55460 to 0.54880, saving model to Results/Best_model/best_model_cnn.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4566 - val_loss: 0.5488\n",
      "Epoch 181/200\n",
      "\u001b[1m560/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.4679\n",
      "Epoch 181: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4688 - val_loss: 0.5695\n",
      "Epoch 182/200\n",
      "\u001b[1m528/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4646\n",
      "Epoch 182: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4648 - val_loss: 0.5788\n",
      "Epoch 183/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4461\n",
      "Epoch 183: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4469 - val_loss: 0.5803\n",
      "Epoch 184/200\n",
      "\u001b[1m557/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.4743\n",
      "Epoch 184: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4743 - val_loss: 0.5565\n",
      "Epoch 185/200\n",
      "\u001b[1m542/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4768\n",
      "Epoch 185: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4774 - val_loss: 0.5969\n",
      "Epoch 186/200\n",
      "\u001b[1m546/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4482\n",
      "Epoch 186: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4493 - val_loss: 0.6016\n",
      "Epoch 187/200\n",
      "\u001b[1m569/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.4826\n",
      "Epoch 187: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4825 - val_loss: 0.5670\n",
      "Epoch 188/200\n",
      "\u001b[1m551/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4633\n",
      "Epoch 188: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4639 - val_loss: 0.5946\n",
      "Epoch 189/200\n",
      "\u001b[1m558/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.4300\n",
      "Epoch 189: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4305 - val_loss: 0.6033\n",
      "Epoch 190/200\n",
      "\u001b[1m560/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.4503\n",
      "Epoch 190: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4508 - val_loss: 0.5610\n",
      "Epoch 191/200\n",
      "\u001b[1m554/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4483\n",
      "Epoch 191: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4488 - val_loss: 0.5917\n",
      "Epoch 192/200\n",
      "\u001b[1m548/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4560\n",
      "Epoch 192: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4561 - val_loss: 0.6401\n",
      "Epoch 193/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5195\n",
      "Epoch 193: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5182 - val_loss: 0.6041\n",
      "Epoch 194/200\n",
      "\u001b[1m541/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4496\n",
      "Epoch 194: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4492 - val_loss: 0.5563\n",
      "Epoch 195/200\n",
      "\u001b[1m553/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4214 \n",
      "Epoch 195: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4224 - val_loss: 0.6172\n",
      "Epoch 196/200\n",
      "\u001b[1m557/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4546\n",
      "Epoch 196: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4545 - val_loss: 0.5828\n",
      "Epoch 197/200\n",
      "\u001b[1m549/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4522\n",
      "Epoch 197: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4527 - val_loss: 0.5781\n",
      "Epoch 198/200\n",
      "\u001b[1m570/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.4858\n",
      "Epoch 198: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4858 - val_loss: 0.5524\n",
      "Epoch 199/200\n",
      "\u001b[1m555/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4680\n",
      "Epoch 199: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4672 - val_loss: 0.6072\n",
      "Epoch 200/200\n",
      "\u001b[1m546/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4360\n",
      "Epoch 200: val_loss did not improve from 0.54880\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4375 - val_loss: 0.5953\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "checkpoint_path = 'Results/Best_model/best_model_cnn.keras'\n",
    "\n",
    "# Set up the ModelCheckpoint callback to save the best model\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_scaled_reshape, y_train, epochs=200, batch_size= 16, validation_split=0.20, callbacks=[checkpoint], verbose=1)\n",
    "\n",
    "# After training, you can load the best model\n",
    "saved_model_cnn = load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba14f032-6034-47ca-a5dc-ed2bdb6fe400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n",
      "R2 score on test set: 0.91\n",
      "RMSE on test set: 0.63\n",
      "MBE: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "y_pred_cnn = saved_model_cnn.predict(X_train_scaled_reshape)\n",
    "y_pred_cnn_reshape = y_pred_cnn.reshape(-1)\n",
    "r2_cnn = r2_score(y_train, y_pred_cnn_reshape)\n",
    "mse_cnn = mean_squared_error(y_train, y_pred_cnn_reshape)\n",
    "rmse_cnn = np.sqrt(mse_cnn)\n",
    "mbe_cnn = np.mean(y_train - y_pred_cnn_reshape)  # MBE\n",
    "\n",
    "# Displaying the best parameters and test set evaluation metrics\n",
    "print(f'R2 score on test set: {r2_cnn:.2f}')\n",
    "print(f'RMSE on test set: {rmse_cnn:.2f}')\n",
    "print(f'MBE: {mbe_cnn:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "428dc35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step\n",
      "R2 score on test set: 0.86\n",
      "RMSE on test set: 0.79\n",
      "MBE: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "y_pred_cnn = saved_model_cnn.predict(X_test_scaled_reshape)\n",
    "y_pred_cnn_reshape = y_pred_cnn.reshape(-1)\n",
    "r2_cnn = r2_score(y_test, y_pred_cnn_reshape)\n",
    "mse_cnn = mean_squared_error(y_test, y_pred_cnn_reshape)\n",
    "rmse_cnn = np.sqrt(mse_cnn)\n",
    "mbe_cnn = np.mean(y_test - y_pred_cnn_reshape)  # MBE\n",
    "\n",
    "# Displaying the best parameters and test set evaluation metrics\n",
    "print(f'R2 score on test set: {r2_cnn:.2f}')\n",
    "print(f'RMSE on test set: {rmse_cnn:.2f}')\n",
    "print(f'MBE: {mbe_cnn:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24547ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff424d18a10>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# visualize the training loss across different epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2420242f-38d0-4192-b59d-f7328bf32475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sccaltter plot for testing data sets\n",
    "plt.scatter(y_test, y_pred_cnn, color='green')\n",
    "plt.xlabel('Observed ETa, mm/day')\n",
    "plt.ylabel('Predicted ETa, mm/day')\n",
    "plt.title('Observed vs Predicted ETa Using LR')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw = 3)  # Adds a reference line\n",
    "\n",
    "# Annotating the plot with the performance metrics\n",
    "textstr = '\\n'.join((\n",
    "    'Testing set',\n",
    "    f'R²: {r2_cnn:.2f}',\n",
    "    f'MSE: {mse_cnn:.2f}',\n",
    "    f'RMSE: {rmse_cnn:.2f} mm/day'\n",
    "))\n",
    "# These are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# Place a text box in upper left in axes coords\n",
    "plt.gca().text(0.04, 0.96, textstr, transform=plt.gca().transAxes, fontsize=12,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3c8b5e4-9df2-401f-bfb1-d6317aefc1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='dd2cb977-1c0f-4f95-a745-a7e1e536085f'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "epochs = len(history.history['loss'])\n",
    "x_data = np.arange(1, epochs + 1)\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "min_val_loss_epoch = np.argmin(history.history['val_loss']) + 1  # +1 because epochs start at 1\n",
    "min_val_loss_value = min(history.history['val_loss'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, epochs)\n",
    "ax.set_ylim(min(min(history.history['loss']), min_val_loss_value),\n",
    "            max(max(history.history['loss']), max(history.history['val_loss'])))\n",
    "\n",
    "line1, = ax.plot([], [], label='Training Loss')\n",
    "line2, = ax.plot([], [], label='Validation Loss')\n",
    "# Plot the vertical line for the best model\n",
    "best_model_line = ax.axvline(x=min_val_loss_epoch, color='green', linestyle='--', alpha=0.7, label='Best Model')\n",
    "ax.annotate(f'Best Model at Epoch {min_val_loss_epoch}', xy=(min_val_loss_epoch, min_val_loss_value), xytext=(min_val_loss_epoch+12, min_val_loss_value+0.12),\n",
    "            arrowprops=dict(facecolor='green', shrink=0.05),)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Validation Loss Over 200 Epochs')\n",
    "\n",
    "def animation_frame(i):\n",
    "    line1.set_data(x_data[:i+1], history.history['loss'][:i+1])\n",
    "    line2.set_data(x_data[:i+1], history.history['val_loss'][:i+1])\n",
    "    # Update the vertical line and annotation to only show when the animation reaches the best model epoch\n",
    "    best_model_line.set_visible(i+1 >= min_val_loss_epoch)\n",
    "    return line1, line2, best_model_line\n",
    "\n",
    "animation = FuncAnimation(fig, animation_frame, frames=np.arange(0, epochs), interval=50, blit=False)\n",
    "\n",
    "plt.show()\n",
    "# Save the animation to your directory\n",
    "#animation.save(r'D:\\My PhD\\ETa Paper\\Animation\\animation.gif', writer='pillow', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd34e7-fadc-4a29-8e1d-1e285191e309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoai",
   "language": "python",
   "name": "geoai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
